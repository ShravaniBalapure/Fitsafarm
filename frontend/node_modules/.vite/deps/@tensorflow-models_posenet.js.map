{
  "version": 3,
  "sources": ["../../@tensorflow-models/posenet/src/base_model.ts", "../../@tensorflow-models/posenet/src/mobilenet.ts", "../../@tensorflow-models/posenet/src/multi_pose/max_heap.ts", "../../@tensorflow-models/posenet/src/multi_pose/build_part_with_score_queue.ts", "../../@tensorflow-models/posenet/src/keypoints.ts", "../../@tensorflow-models/posenet/src/multi_pose/util.ts", "../../@tensorflow-models/posenet/src/multi_pose/decode_pose.ts", "../../@tensorflow-models/posenet/src/multi_pose/decode_multiple_poses.ts", "../../@tensorflow-models/posenet/src/single_pose/argmax2d.ts", "../../@tensorflow-models/posenet/src/single_pose/util.ts", "../../@tensorflow-models/posenet/src/single_pose/decode_single_pose.ts", "../../@tensorflow-models/posenet/src/checkpoints.ts", "../../@tensorflow-models/posenet/src/resnet.ts", "../../@tensorflow-models/posenet/src/util.ts", "../../@tensorflow-models/posenet/src/posenet_model.ts", "../../@tensorflow-models/posenet/src/version.ts"],
  "sourcesContent": ["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport {PoseNetOutputStride} from './types';\n\n/**\n * PoseNet supports using various convolution neural network models\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\n * The following BaseModel interface defines a unified interface for\n * creating such PoseNet base models. Currently both MobileNet (in\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\n * interface. New base models that conform to the BaseModel interface can be\n * added to PoseNet.\n */\nexport abstract class BaseModel {\n  constructor(\n      protected readonly model: tfconv.GraphModel,\n      public readonly outputStride: PoseNetOutputStride) {\n    const inputShape =\n        this.model.inputs[0].shape as [number, number, number, number];\n    tf.util.assert(\n        (inputShape[1] === -1) && (inputShape[2] === -1),\n        () => `Input shape [${inputShape[1]}, ${inputShape[2]}] ` +\n            `must both be equal to or -1`);\n  }\n\n  abstract preprocessInput(input: tf.Tensor3D): tf.Tensor3D;\n\n  /**\n   * Predicts intermediate Tensor representations.\n   *\n   * @param input The input RGB image of the base model.\n   * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\n   *\n   * @return A dictionary of base model's intermediate predictions.\n   * The returned dictionary should contains the following elements:\n   * heatmapScores: A Tensor3D that represents the heatmapScores.\n   * offsets: A Tensor3D that represents the offsets.\n   * displacementFwd: A Tensor3D that represents the forward displacement.\n   * displacementBwd: A Tensor3D that represents the backward displacement.\n   */\n  predict(input: tf.Tensor3D): {\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  } {\n    return tf.tidy(() => {\n      const asFloat = this.preprocessInput(tf.cast(input, 'float32'));\n      const asBatch = tf.expandDims(asFloat, 0);\n      const results = this.model.predict(asBatch) as tf.Tensor4D[];\n      const results3d: tf.Tensor3D[] = results.map(y => tf.squeeze(y, [0]));\n\n      const namedResults = this.nameOutputResults(results3d);\n\n      return {\n        heatmapScores: tf.sigmoid(namedResults.heatmap),\n        offsets: namedResults.offsets,\n        displacementFwd: namedResults.displacementFwd,\n        displacementBwd: namedResults.displacementBwd\n      };\n    });\n  }\n\n  // Because MobileNet and ResNet predict() methods output a different order for\n  // these values, we have a method that needs to be implemented to order them.\n  abstract nameOutputResults(results: tf.Tensor3D[]): {\n    heatmap: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  };\n\n  /**\n   * Releases the CPU and GPU memory allocated by the model.\n   */\n  dispose() {\n    this.model.dispose();\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BaseModel} from './base_model';\n\nexport class MobileNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    // Normalize the pixels [0, 255] to be between [-1, 1].\n    return tf.tidy(() => tf.sub(tf.div(input, 127.5), 1.0));\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [offsets, heatmap, displacementFwd, displacementBwd] = results;\n    return {offsets, heatmap, displacementFwd, displacementBwd};\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\n\nfunction half(k: number) {\n  return Math.floor(k / 2);\n}\n\nexport class MaxHeap<T> {\n  private priorityQueue: T[];\n  private numberOfElements: number;\n  private getElementValue: (element: T) => number;\n\n  constructor(maxSize: number, getElementValue: (element: T) => number) {\n    this.priorityQueue = new Array(maxSize);\n    this.numberOfElements = -1;\n    this.getElementValue = getElementValue;\n  }\n\n  public enqueue(x: T): void {\n    this.priorityQueue[++this.numberOfElements] = x;\n    this.swim(this.numberOfElements);\n  }\n\n  public dequeue(): T {\n    const max = this.priorityQueue[0];\n    this.exchange(0, this.numberOfElements--);\n    this.sink(0);\n    this.priorityQueue[this.numberOfElements + 1] = null;\n    return max;\n  }\n\n  public empty(): boolean {\n    return this.numberOfElements === -1;\n  }\n\n  public size(): number {\n    return this.numberOfElements + 1;\n  }\n\n  public all(): T[] {\n    return this.priorityQueue.slice(0, this.numberOfElements + 1);\n  }\n\n  public max(): T {\n    return this.priorityQueue[0];\n  }\n\n  private swim(k: number): void {\n    while (k > 0 && this.less(half(k), k)) {\n      this.exchange(k, half(k));\n      k = half(k);\n    }\n  }\n\n  private sink(k: number): void {\n    while (2 * k <= this.numberOfElements) {\n      let j = 2 * k;\n      if (j < this.numberOfElements && this.less(j, j + 1)) {\n        j++;\n      }\n      if (!this.less(k, j)) {\n        break;\n      }\n      this.exchange(k, j);\n      k = j;\n    }\n  }\n\n  private getValueAt(i: number): number {\n    return this.getElementValue(this.priorityQueue[i]);\n  }\n\n  private less(i: number, j: number): boolean {\n    return this.getValueAt(i) < this.getValueAt(j);\n  }\n\n  private exchange(i: number, j: number): void {\n    const t = this.priorityQueue[i];\n    this.priorityQueue[i] = this.priorityQueue[j];\n    this.priorityQueue[j] = t;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {PartWithScore, TensorBuffer3D} from '../types';\n\nimport {MaxHeap} from './max_heap';\n\nfunction scoreIsMaximumInLocalWindow(\n    keypointId: number, score: number, heatmapY: number, heatmapX: number,\n    localMaximumRadius: number, scores: TensorBuffer3D): boolean {\n  const [height, width] = scores.shape;\n\n  let localMaximum = true;\n  const yStart = Math.max(heatmapY - localMaximumRadius, 0);\n  const yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\n  for (let yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\n    const xStart = Math.max(heatmapX - localMaximumRadius, 0);\n    const xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\n    for (let xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\n      if (scores.get(yCurrent, xCurrent, keypointId) > score) {\n        localMaximum = false;\n        break;\n      }\n    }\n    if (!localMaximum) {\n      break;\n    }\n  }\n\n  return localMaximum;\n}\n\n/**\n * Builds a priority queue with part candidate positions for a specific image in\n * the batch. For this we find all local maxima in the score maps with score\n * values above a threshold. We create a single priority queue across all parts.\n */\nexport function buildPartWithScoreQueue(\n    scoreThreshold: number, localMaximumRadius: number,\n    scores: TensorBuffer3D): MaxHeap<PartWithScore> {\n  const [height, width, numKeypoints] = scores.shape;\n\n  const queue = new MaxHeap<PartWithScore>(\n      height * width * numKeypoints, ({score}) => score);\n\n  for (let heatmapY = 0; heatmapY < height; ++heatmapY) {\n    for (let heatmapX = 0; heatmapX < width; ++heatmapX) {\n      for (let keypointId = 0; keypointId < numKeypoints; ++keypointId) {\n        const score = scores.get(heatmapY, heatmapX, keypointId);\n\n        // Only consider parts with score greater or equal to threshold as\n        // root candidates.\n        if (score < scoreThreshold) {\n          continue;\n        }\n\n        // Only consider keypoints whose score is maximum in a local window.\n        if (scoreIsMaximumInLocalWindow(\n                keypointId, score, heatmapY, heatmapX, localMaximumRadius,\n                scores)) {\n          queue.enqueue({score, part: {heatmapY, heatmapX, id: keypointId}});\n        }\n      }\n    }\n  }\n\n  return queue;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport type Tuple<T> = [T, T];\nexport type StringTuple = Tuple<string>;\nexport type NumberTuple = Tuple<number>;\n\nexport const partNames = [\n  'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\n  'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\n  'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\n];\n\nexport const NUM_KEYPOINTS = partNames.length;\n\nexport interface NumberDict {\n  [jointName: string]: number;\n}\n\nexport const partIds =\n    partNames.reduce((result: NumberDict, jointName, i): NumberDict => {\n      result[jointName] = i;\n      return result;\n    }, {}) as NumberDict;\n\nconst connectedPartNames: StringTuple[] = [\n  ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\n  ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\n  ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\n  ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\n  ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\n];\n\n/*\n * Define the skeleton. This defines the parent->child relationships of our\n * tree. Arbitrarily this defines the nose as the root of the tree, however\n * since we will infer the displacement for both parent->child and\n * child->parent, we can define the tree root as any node.\n */\nexport const poseChain: StringTuple[] = [\n  ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\n  ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\n  ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\n  ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\n  ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\n  ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\n  ['rightKnee', 'rightAnkle']\n];\n\nexport const connectedPartIndices = connectedPartNames.map(\n    ([jointNameA, jointNameB]) => ([partIds[jointNameA], partIds[jointNameB]]));\n\nexport const partChannels: string[] = [\n  'left_face',\n  'right_face',\n  'right_upper_leg_front',\n  'right_lower_leg_back',\n  'right_upper_leg_back',\n  'left_lower_leg_front',\n  'left_upper_leg_front',\n  'left_upper_leg_back',\n  'left_lower_leg_back',\n  'right_feet',\n  'right_lower_leg_front',\n  'left_feet',\n  'torso_front',\n  'torso_back',\n  'right_upper_arm_front',\n  'right_upper_arm_back',\n  'right_lower_arm_back',\n  'left_lower_arm_front',\n  'left_upper_arm_front',\n  'left_upper_arm_back',\n  'left_lower_arm_back',\n  'right_hand',\n  'right_lower_arm_front',\n  'left_hand'\n];\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Part, TensorBuffer3D, Vector2D} from '../types';\n\nexport function getOffsetPoint(\n    y: number, x: number, keypoint: number, offsets: TensorBuffer3D): Vector2D {\n  return {\n    y: offsets.get(y, x, keypoint),\n    x: offsets.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getImageCoords(\n    part: Part, outputStride: number, offsets: TensorBuffer3D): Vector2D {\n  const {heatmapY, heatmapX, id: keypoint} = part;\n  const {y, x} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets);\n  return {\n    x: part.heatmapX * outputStride + x,\n    y: part.heatmapY * outputStride + y\n  };\n}\n\nexport function fillArray<T>(element: T, size: number): T[] {\n  const result: T[] = new Array(size);\n\n  for (let i = 0; i < size; i++) {\n    result[i] = element;\n  }\n\n  return result;\n}\n\nexport function clamp(a: number, min: number, max: number): number {\n  if (a < min) {\n    return min;\n  }\n  if (a > max) {\n    return max;\n  }\n  return a;\n}\n\nexport function squaredDistance(\n    y1: number, x1: number, y2: number, x2: number): number {\n  const dy = y2 - y1;\n  const dx = x2 - x1;\n  return dy * dy + dx * dx;\n}\n\nexport function addVectors(a: Vector2D, b: Vector2D): Vector2D {\n  return {x: a.x + b.x, y: a.y + b.y};\n}\n\nexport function clampVector(a: Vector2D, min: number, max: number): Vector2D {\n  return {y: clamp(a.y, min, max), x: clamp(a.x, min, max)};\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumberTuple, partIds, partNames, poseChain} from '../keypoints';\nimport {Keypoint, PartWithScore, TensorBuffer3D, Vector2D} from '../types';\n\nimport {clamp, getOffsetPoint} from './util';\nimport {addVectors, getImageCoords} from './util';\n\nconst parentChildrenTuples: NumberTuple[] = poseChain.map(\n    ([parentJoinName, childJoinName]): NumberTuple =>\n        ([partIds[parentJoinName], partIds[childJoinName]]));\n\nconst parentToChildEdges: number[] =\n    parentChildrenTuples.map(([, childJointId]) => childJointId);\n\nconst childToParentEdges: number[] =\n    parentChildrenTuples.map(([\n                               parentJointId,\n                             ]) => parentJointId);\n\nfunction getDisplacement(\n    edgeId: number, point: Vector2D, displacements: TensorBuffer3D): Vector2D {\n  const numEdges = displacements.shape[2] / 2;\n  return {\n    y: displacements.get(point.y, point.x, edgeId),\n    x: displacements.get(point.y, point.x, numEdges + edgeId)\n  };\n}\n\nfunction getStridedIndexNearPoint(\n    point: Vector2D, outputStride: number, height: number,\n    width: number): Vector2D {\n  return {\n    y: clamp(Math.round(point.y / outputStride), 0, height - 1),\n    x: clamp(Math.round(point.x / outputStride), 0, width - 1)\n  };\n}\n\n/**\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\n * that the position of the `idSource` part is already known. For this, we\n * follow the displacement vector from the source to target part (stored in\n * the `i`-t channel of the displacement tensor). The displaced keypoint\n * vector is refined using the offset vector by `offsetRefineStep` times.\n */\nfunction traverseToTargetKeypoint(\n    edgeId: number, sourceKeypoint: Keypoint, targetKeypointId: number,\n    scoresBuffer: TensorBuffer3D, offsets: TensorBuffer3D, outputStride: number,\n    displacements: TensorBuffer3D, offsetRefineStep = 2): Keypoint {\n  const [height, width] = scoresBuffer.shape;\n\n  // Nearest neighbor interpolation for the source->target displacements.\n  const sourceKeypointIndices = getStridedIndexNearPoint(\n      sourceKeypoint.position, outputStride, height, width);\n\n  const displacement =\n      getDisplacement(edgeId, sourceKeypointIndices, displacements);\n\n  const displacedPoint = addVectors(sourceKeypoint.position, displacement);\n  let targetKeypoint = displacedPoint;\n  for (let i = 0; i < offsetRefineStep; i++) {\n    const targetKeypointIndices =\n        getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n\n    const offsetPoint = getOffsetPoint(\n        targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId,\n        offsets);\n\n    targetKeypoint = addVectors(\n        {\n          x: targetKeypointIndices.x * outputStride,\n          y: targetKeypointIndices.y * outputStride\n        },\n        {x: offsetPoint.x, y: offsetPoint.y});\n  }\n  const targetKeyPointIndices =\n      getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n  const score = scoresBuffer.get(\n      targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\n\n  return {position: targetKeypoint, part: partNames[targetKeypointId], score};\n}\n\n/**\n * Follows the displacement fields to decode the full pose of the object\n * instance given the position of a part that acts as root.\n *\n * @return An array of decoded keypoints and their scores for a single pose\n */\nexport function decodePose(\n    root: PartWithScore, scores: TensorBuffer3D, offsets: TensorBuffer3D,\n    outputStride: number, displacementsFwd: TensorBuffer3D,\n    displacementsBwd: TensorBuffer3D): Keypoint[] {\n  const numParts = scores.shape[2];\n  const numEdges = parentToChildEdges.length;\n\n  const instanceKeypoints: Keypoint[] = new Array(numParts);\n  // Start a new detection instance at the position of the root.\n  const {part: rootPart, score: rootScore} = root;\n  const rootPoint = getImageCoords(rootPart, outputStride, offsets);\n\n  instanceKeypoints[rootPart.id] = {\n    score: rootScore,\n    part: partNames[rootPart.id],\n    position: rootPoint\n  };\n\n  // Decode the part positions upwards in the tree, following the backward\n  // displacements.\n  for (let edge = numEdges - 1; edge >= 0; --edge) {\n    const sourceKeypointId = parentToChildEdges[edge];\n    const targetKeypointId = childToParentEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsBwd);\n    }\n  }\n\n  // Decode the part positions downwards in the tree, following the forward\n  // displacements.\n  for (let edge = 0; edge < numEdges; ++edge) {\n    const sourceKeypointId = childToParentEdges[edge];\n    const targetKeypointId = parentToChildEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsFwd);\n    }\n  }\n\n  return instanceKeypoints;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Keypoint, Pose, TensorBuffer3D} from '../types';\n\nimport {buildPartWithScoreQueue} from './build_part_with_score_queue';\nimport {decodePose} from './decode_pose';\nimport {getImageCoords, squaredDistance} from './util';\n\nfunction withinNmsRadiusOfCorrespondingPoint(\n    poses: Pose[], squaredNmsRadius: number, {x, y}: {x: number, y: number},\n    keypointId: number): boolean {\n  return poses.some(({keypoints}) => {\n    const correspondingKeypoint = keypoints[keypointId].position;\n    return squaredDistance(\n               y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\n        squaredNmsRadius;\n  });\n}\n\n/* Score the newly proposed object instance without taking into account\n * the scores of the parts that overlap with any previously detected\n * instance.\n */\nfunction getInstanceScore(\n    existingPoses: Pose[], squaredNmsRadius: number,\n    instanceKeypoints: Keypoint[]): number {\n  let notOverlappedKeypointScores = instanceKeypoints.reduce(\n      (result, {position, score}, keypointId): number => {\n        if (!withinNmsRadiusOfCorrespondingPoint(\n                existingPoses, squaredNmsRadius, position, keypointId)) {\n          result += score;\n        }\n        return result;\n      }, 0.0);\n\n  return notOverlappedKeypointScores /= instanceKeypoints.length;\n}\n\n// A point (y, x) is considered as root part candidate if its score is a\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\n// kLocalMaximumRadius.\nconst kLocalMaximumRadius = 1;\n\n/**\n * Detects multiple poses and finds their parts from part scores and\n * displacement vectors. It returns up to `maxDetections` object instance\n * detections in decreasing root score order. It works as follows: We first\n * create a priority queue with local part score maxima above\n * `scoreThreshold`, considering all parts at the same time. Then we\n * iteratively pull the top  element of the queue (in decreasing score order)\n * and treat it as a root candidate for a new object instance. To avoid\n * duplicate detections, we reject the root candidate if it is within a disk\n * of `nmsRadius` pixels from the corresponding part of a previously detected\n * instance, which is a form of part-based non-maximum suppression (NMS). If\n * the root candidate passes the NMS check, we start a new object instance\n * detection, treating the corresponding part as root and finding the\n * positions of the remaining parts by following the displacement vectors\n * along the tree-structured part graph. We assign to the newly detected\n * instance a score equal to the sum of scores of its parts which have not\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\n * pixels away from the corresponding part of all previously detected\n * instances), divided by the total number of parts `numParts`.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param displacementsFwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the forward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param displacementsBwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the backward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @param maxPoseDetections Maximum number of returned instance detections per\n * image.\n *\n * @param scoreThreshold Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5.\n *\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\n * strictly positive. Two parts suppress each other if they are less than\n * `nmsRadius` pixels away. Defaults to 20.\n *\n * @return An array of poses and their scores, each containing keypoints and\n * the corresponding keypoint scores.\n */\nexport function decodeMultiplePoses(\n    scoresBuffer: TensorBuffer3D, offsetsBuffer: TensorBuffer3D,\n    displacementsFwdBuffer: TensorBuffer3D,\n    displacementsBwdBuffer: TensorBuffer3D, outputStride: number,\n    maxPoseDetections: number, scoreThreshold = 0.5, nmsRadius = 20): Pose[] {\n  const poses: Pose[] = [];\n\n  const queue = buildPartWithScoreQueue(\n      scoreThreshold, kLocalMaximumRadius, scoresBuffer);\n\n  const squaredNmsRadius = nmsRadius * nmsRadius;\n\n  // Generate at most maxDetections object instances per image in\n  // decreasing root part score order.\n  while (poses.length < maxPoseDetections && !queue.empty()) {\n    // The top element in the queue is the next root candidate.\n    const root = queue.dequeue();\n\n    // Part-based non-maximum suppression: We reject a root candidate if it\n    // is within a disk of `nmsRadius` pixels from the corresponding part of\n    // a previously detected instance.\n    const rootImageCoords =\n        getImageCoords(root.part, outputStride, offsetsBuffer);\n    if (withinNmsRadiusOfCorrespondingPoint(\n            poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\n      continue;\n    }\n\n    // Start a new detection instance at the position of the root.\n    const keypoints = decodePose(\n        root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer,\n        displacementsBwdBuffer);\n\n    const score = getInstanceScore(poses, squaredNmsRadius, keypoints);\n\n    poses.push({keypoints, score});\n  }\n\n  return poses;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nfunction mod(a: tf.Tensor1D, b: number): tf.Tensor1D {\n  return tf.tidy(() => {\n    const floored = tf.div(a, tf.scalar(b, 'int32'));\n\n    return tf.sub(a, tf.mul(floored, tf.scalar(b, 'int32')));\n  });\n}\n\nexport function argmax2d(inputs: tf.Tensor3D): tf.Tensor2D {\n  const [height, width, depth] = inputs.shape;\n\n  return tf.tidy(() => {\n    const reshaped = tf.reshape(inputs, [height * width, depth]);\n    const coords = tf.argMax(reshaped, 0);\n\n    const yCoords = tf.expandDims(tf.div(coords, tf.scalar(width, 'int32')), 1);\n    const xCoords = tf.expandDims(mod(coords as tf.Tensor1D, width), 1);\n\n    return tf.concat([yCoords, xCoords], 1);\n  }) as tf.Tensor2D;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Vector2D} from '../types';\n\nexport function getPointsConfidence(\n    heatmapScores: tf.TensorBuffer<tf.Rank.R3>,\n    heatMapCoords: tf.TensorBuffer<tf.Rank.R2>): Float32Array {\n  const numKeypoints = heatMapCoords.shape[0];\n  const result = new Float32Array(numKeypoints);\n\n  for (let keypoint = 0; keypoint < numKeypoints; keypoint++) {\n    const y = heatMapCoords.get(keypoint, 0);\n    const x = heatMapCoords.get(keypoint, 1);\n    result[keypoint] = heatmapScores.get(y, x, keypoint);\n  }\n\n  return result;\n}\n\nfunction getOffsetPoint(\n    y: number, x: number, keypoint: number,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): Vector2D {\n  return {\n    y: offsetsBuffer.get(y, x, keypoint),\n    x: offsetsBuffer.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getOffsetVectors(\n    heatMapCoordsBuffer: tf.TensorBuffer<tf.Rank.R2>,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): tf.Tensor2D {\n  const result: number[] = [];\n\n  for (let keypoint = 0; keypoint < NUM_KEYPOINTS; keypoint++) {\n    const heatmapY = heatMapCoordsBuffer.get(keypoint, 0).valueOf();\n    const heatmapX = heatMapCoordsBuffer.get(keypoint, 1).valueOf();\n\n    const {x, y} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsetsBuffer);\n\n    result.push(y);\n    result.push(x);\n  }\n\n  return tf.tensor2d(result, [NUM_KEYPOINTS, 2]);\n}\n\nexport function getOffsetPoints(\n    heatMapCoordsBuffer: tf.TensorBuffer<tf.Rank.R2>, outputStride: number,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): tf.Tensor2D {\n  return tf.tidy(() => {\n    const offsetVectors = getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer);\n\n    return tf\n        .add(tf\n          .cast(tf\n            .mul(heatMapCoordsBuffer.toTensor(), tf.scalar(outputStride,\n              'int32')), 'float32'), offsetVectors);\n  });\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {partNames} from '../keypoints';\nimport {Keypoint, Pose, PoseNetOutputStride} from '../types';\n\nimport {argmax2d} from './argmax2d';\nimport {getOffsetPoints, getPointsConfidence} from './util';\n\n/**\n * Detects a single pose and finds its parts from part scores and offset\n * vectors. It returns a single pose detection. It works as follows:\n * argmax2d is done on the scores to get the y and x index in the heatmap\n * with the highest score for each part, which is essentially where the\n * part is most likely to exist. This produces a tensor of size 17x2, with\n * each row being the y and x index in the heatmap for each keypoint.\n * The offset vector for each for each part is retrieved by getting the\n * y and x from the offsets corresponding to the y and x index in the\n * heatmap for that part. This produces a tensor of size 17x2, with each\n * row being the offset vector for the corresponding keypoint.\n * To get the keypoint, each part’s heatmap y and x are multiplied\n * by the output stride then added to their corresponding offset vector,\n * which is in the same scale as the original image.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @return A promise that resolves with single pose with a confidence score,\n * which contains an array of keypoints indexed by part id, each with a score\n * and position.\n */\nexport async function decodeSinglePose(\n    heatmapScores: tf.Tensor3D, offsets: tf.Tensor3D,\n    outputStride: PoseNetOutputStride): Promise<Pose> {\n  let totalScore = 0.0;\n\n  const heatmapValues = argmax2d(heatmapScores);\n\n  const allTensorBuffers = await Promise.all(\n      [heatmapScores.buffer(), offsets.buffer(), heatmapValues.buffer()]);\n\n  const scoresBuffer = allTensorBuffers[0];\n  const offsetsBuffer = allTensorBuffers[1];\n  const heatmapValuesBuffer = allTensorBuffers[2];\n\n  const offsetPoints =\n      getOffsetPoints(heatmapValuesBuffer, outputStride, offsetsBuffer);\n  const offsetPointsBuffer = await offsetPoints.buffer();\n\n  const keypointConfidence =\n      Array.from(getPointsConfidence(scoresBuffer, heatmapValuesBuffer));\n\n  const keypoints = keypointConfidence.map((score, keypointId): Keypoint => {\n    totalScore += score;\n    return {\n      position: {\n        y: offsetPointsBuffer.get(keypointId, 0),\n        x: offsetPointsBuffer.get(keypointId, 1)\n      },\n      part: partNames[keypointId],\n      score\n    };\n  });\n\n  heatmapValues.dispose();\n  offsetPoints.dispose();\n\n  return {keypoints, score: totalScore / keypoints.length};\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nconst MOBILENET_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/';\nconst RESNET50_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/';\n\n// The PoseNet 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function resNet50Checkpoint(stride: number, quantBytes: number): string {\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n  if (quantBytes === 4) {\n    return RESNET50_BASE_URL + `float/` + graphJson;\n  } else {\n    return RESNET50_BASE_URL + `quant${quantBytes}/` + graphJson;\n  }\n}\n\n// The PoseNet 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function mobileNetCheckpoint(\n    stride: number, multiplier: number, quantBytes: number): string {\n  const toStr: {[key: number]: string} = {1.0: '100', 0.75: '075', 0.50: '050'};\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n  if (quantBytes === 4) {\n    return MOBILENET_BASE_URL + `float/${toStr[multiplier]}/` + graphJson;\n  } else {\n    return MOBILENET_BASE_URL + `quant${quantBytes}/${toStr[multiplier]}/` +\n        graphJson;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\n\nconst imageNetMean = [-123.15, -115.90, -103.06];\n\nexport class ResNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    return tf.add(input, imageNetMean);\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [displacementFwd, displacementBwd, offsets, heatmap] = results;\n    return {offsets, heatmap, displacementFwd, displacementBwd};\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {connectedPartIndices} from './keypoints';\nimport {InputResolution, Keypoint, Padding, Pose, PosenetInput, PoseNetOutputStride, TensorBuffer3D, Vector2D} from './types';\n\nfunction eitherPointDoesntMeetConfidence(\n    a: number, b: number, minConfidence: number): boolean {\n  return (a < minConfidence || b < minConfidence);\n}\n\nexport function getAdjacentKeyPoints(\n    keypoints: Keypoint[], minConfidence: number): Keypoint[][] {\n  return connectedPartIndices.reduce(\n      (result: Keypoint[][], [leftJoint, rightJoint]): Keypoint[][] => {\n        if (eitherPointDoesntMeetConfidence(\n                keypoints[leftJoint].score, keypoints[rightJoint].score,\n                minConfidence)) {\n          return result;\n        }\n\n        result.push([keypoints[leftJoint], keypoints[rightJoint]]);\n\n        return result;\n      }, []);\n}\n\nconst {NEGATIVE_INFINITY, POSITIVE_INFINITY} = Number;\nexport function getBoundingBox(keypoints: Keypoint[]):\n    {maxX: number, maxY: number, minX: number, minY: number} {\n  return keypoints.reduce(({maxX, maxY, minX, minY}, {position: {x, y}}) => {\n    return {\n      maxX: Math.max(maxX, x),\n      maxY: Math.max(maxY, y),\n      minX: Math.min(minX, x),\n      minY: Math.min(minY, y)\n    };\n  }, {\n    maxX: NEGATIVE_INFINITY,\n    maxY: NEGATIVE_INFINITY,\n    minX: POSITIVE_INFINITY,\n    minY: POSITIVE_INFINITY\n  });\n}\n\nexport function getBoundingBoxPoints(keypoints: Keypoint[]): Vector2D[] {\n  const {minX, minY, maxX, maxY} = getBoundingBox(keypoints);\n  return [\n    {x: minX, y: minY}, {x: maxX, y: minY}, {x: maxX, y: maxY},\n    {x: minX, y: maxY}\n  ];\n}\n\nexport async function toTensorBuffers3D(tensors: tf.Tensor3D[]):\n    Promise<TensorBuffer3D[]> {\n  return Promise.all(tensors.map(tensor => tensor.buffer()));\n}\n\nexport function scalePose(\n    pose: Pose, scaleY: number, scaleX: number, offsetY = 0,\n    offsetX = 0): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(({score, part, position}) => ({\n                                    score,\n                                    part,\n                                    position: {\n                                      x: position.x * scaleX + offsetX,\n                                      y: position.y * scaleY + offsetY\n                                    }\n                                  }))\n  };\n}\n\nexport function scalePoses(\n    poses: Pose[], scaleY: number, scaleX: number, offsetY = 0, offsetX = 0) {\n  if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\n    return poses;\n  }\n  return poses.map(pose => scalePose(pose, scaleY, scaleX, offsetY, offsetX));\n}\n\nexport function flipPoseHorizontal(pose: Pose, imageWidth: number): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(\n        ({score, part, position}) => ({\n          score,\n          part,\n          position: {x: imageWidth - 1 - position.x, y: position.y}\n        }))\n  };\n}\n\nexport function flipPosesHorizontal(poses: Pose[], imageWidth: number) {\n  if (imageWidth <= 0) {\n    return poses;\n  }\n  return poses.map(pose => flipPoseHorizontal(pose, imageWidth));\n}\n\nexport function toValidInputResolution(\n    inputResolution: number, outputStride: PoseNetOutputStride): number {\n  if (isValidInputResolution(inputResolution, outputStride)) {\n    return inputResolution;\n  }\n\n  return Math.floor(inputResolution / outputStride) * outputStride + 1;\n}\n\nexport function validateInputResolution(inputResolution: InputResolution) {\n  tf.util.assert(\n      typeof inputResolution === 'number' ||\n          typeof inputResolution === 'object',\n      () => `Invalid inputResolution ${inputResolution}. ` +\n          `Should be a number or an object with width and height`);\n\n  if (typeof inputResolution === 'object') {\n    tf.util.assert(\n        typeof inputResolution.width === 'number',\n        () => `inputResolution.width has a value of ${\n            inputResolution.width} which is invalid; it must be a number`);\n    tf.util.assert(\n        typeof inputResolution.height === 'number',\n        () => `inputResolution.height has a value of ${\n            inputResolution.height} which is invalid; it must be a number`);\n  }\n}\n\nexport function getValidInputResolutionDimensions(\n    inputResolution: InputResolution,\n    outputStride: PoseNetOutputStride): [number, number] {\n  validateInputResolution(inputResolution);\n  if (typeof inputResolution === 'object') {\n    return [\n      toValidInputResolution(inputResolution.height, outputStride),\n      toValidInputResolution(inputResolution.width, outputStride),\n    ];\n  } else {\n    return [\n      toValidInputResolution(inputResolution, outputStride),\n      toValidInputResolution(inputResolution, outputStride),\n    ];\n  }\n}\n\nconst VALID_OUTPUT_STRIDES: PoseNetOutputStride[] = [8, 16, 32];\nexport function assertValidOutputStride(outputStride: PoseNetOutputStride) {\n  tf.util.assert(\n      typeof outputStride === 'number', () => 'outputStride is not a number');\n  tf.util.assert(\n      VALID_OUTPUT_STRIDES.indexOf(outputStride) >= 0,\n      () => `outputStride of ${outputStride} is invalid. ` +\n          `It must be either 8, 16, or 32`);\n}\n\nfunction isValidInputResolution(\n    resolution: number, outputStride: number): boolean {\n  return (resolution - 1) % outputStride === 0;\n}\n\nexport function assertValidResolution(\n    resolution: [number, number], outputStride: number) {\n  tf.util.assert(\n      typeof resolution[0] === 'number' && typeof resolution[1] === 'number',\n      () => `both resolution values must be a number but had values ${\n          resolution}`);\n\n  tf.util.assert(\n      isValidInputResolution(resolution[0], outputStride),\n      () => `height of ${resolution[0]} is invalid for output stride ` +\n          `${outputStride}.`);\n\n  tf.util.assert(\n      isValidInputResolution(resolution[1], outputStride),\n      () => `width of ${resolution[1]} is invalid for output stride ` +\n          `${outputStride}.`);\n}\n\nexport function getInputTensorDimensions(input: PosenetInput):\n    [number, number] {\n  return input instanceof tf.Tensor ? [input.shape[0], input.shape[1]] :\n                                      [input.height, input.width];\n}\n\nexport function toInputTensor(input: PosenetInput) {\n  return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\n}\n\nexport function toResizedInputTensor(\n    input: PosenetInput, resizeHeight: number, resizeWidth: number,\n    flipHorizontal: boolean): tf.Tensor3D {\n  return tf.tidy(() => {\n    const imageTensor = toInputTensor(input);\n\n    if (flipHorizontal) {\n      return tf.image.resizeBilinear(tf.reverse(imageTensor, 1), [resizeHeight, resizeWidth]);\n    } else {\n      return tf.image.resizeBilinear(imageTensor, [resizeHeight, resizeWidth]);\n    }\n  });\n}\n\nexport function padAndResizeTo(\n    input: PosenetInput, [targetH, targetW]: [number, number]):\n    {resized: tf.Tensor3D, padding: Padding} {\n  const [height, width] = getInputTensorDimensions(input);\n  const targetAspect = targetW / targetH;\n  const aspect = width / height;\n  let [padT, padB, padL, padR] = [0, 0, 0, 0];\n  if (aspect < targetAspect) {\n    // pads the width\n    padT = 0;\n    padB = 0;\n    padL = Math.round(0.5 * (targetAspect * height - width));\n    padR = Math.round(0.5 * (targetAspect * height - width));\n  } else {\n    // pads the height\n    padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padL = 0;\n    padR = 0;\n  }\n\n  const resized: tf.Tensor3D = tf.tidy(() => {\n    let imageTensor = toInputTensor(input);\n    imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\n\n    return tf.image.resizeBilinear(imageTensor, [targetH, targetW]);\n  });\n\n  return {resized, padding: {top: padT, left: padL, right: padR, bottom: padB}};\n}\n\nexport function scaleAndFlipPoses(\n    poses: Pose[], [height, width]: [number, number],\n    [inputResolutionHeight, inputResolutionWidth]: [number, number],\n    padding: Padding, flipHorizontal: boolean): Pose[] {\n  const scaleY =\n      (height + padding.top + padding.bottom) / (inputResolutionHeight);\n  const scaleX =\n      (width + padding.left + padding.right) / (inputResolutionWidth);\n\n  const scaledPoses =\n      scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\n\n  if (flipHorizontal) {\n    return flipPosesHorizontal(scaledPoses, width);\n  } else {\n    return scaledPoses;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\nimport {mobileNetCheckpoint, resNet50Checkpoint} from './checkpoints';\nimport {MobileNet} from './mobilenet';\nimport {decodeMultiplePoses} from './multi_pose/decode_multiple_poses';\nimport {ResNet} from './resnet';\nimport {decodeSinglePose} from './single_pose/decode_single_pose';\nimport {InputResolution, MobileNetMultiplier, Pose, PoseNetArchitecture, PosenetInput, PoseNetOutputStride, PoseNetQuantBytes} from './types';\nimport {assertValidOutputStride, assertValidResolution, getInputTensorDimensions, getValidInputResolutionDimensions, padAndResizeTo, scaleAndFlipPoses, toTensorBuffers3D, validateInputResolution} from './util';\n\n/**\n * PoseNet model loading is configurable using the following config dictionary.\n *\n * `architecture`: PoseNetArchitecture. It determines wich PoseNet architecture\n * to load. The supported architectures are: MobileNetV1 and ResNet.\n *\n * `outputStride`: Specifies the output stride of the PoseNet model.\n * The smaller the value, the larger the output resolution, and more accurate\n * the model at the cost of speed.  Set this to a larger value to increase speed\n * at the cost of accuracy. Stride 32 is supported for ResNet and\n * stride 8,16,32 are supported for various MobileNetV1 models.\n *\n * * `inputResolution`: A number or an Object of type {width: number, height:\n * number}. Specifies the size the input image is scaled to before feeding it\n * through the PoseNet model.  The larger the value, more accurate the model at\n * the cost of speed. Set this to a smaller value to increase speed at the cost\n * of accuracy. If a number is provided, the input will be resized and padded to\n * be a square with the same width and height.  If width and height are\n * provided, the input will be resized and padded to the specified width and\n * height.\n *\n * `multiplier`: An optional number with values: 1.01, 1.0, 0.75, or\n * 0.50. The value is used only by MobileNet architecture. It is the float\n * multiplier for the depth (number of channels) for all convolution ops.\n * The larger the value, the larger the size of the layers, and more accurate\n * the model at the cost of speed. Set this to a smaller value to increase speed\n * at the cost of accuracy.\n *\n * `modelUrl`: An optional string that specifies custom url of the model. This\n * is useful for area/countries that don't have access to the model hosted on\n * GCP.\n *\n * `quantBytes`: An opional number with values: 1, 2, or 4.  This parameter\n * affects weight quantization in the models. The available options are\n * 1 byte, 2 bytes, and 4 bytes. The higher the value, the larger the model size\n * and thus the longer the loading time, the lower the value, the shorter the\n * loading time but lower the accuracy.\n */\nexport interface ModelConfig {\n  architecture: PoseNetArchitecture;\n  outputStride: PoseNetOutputStride;\n  inputResolution: InputResolution;\n  multiplier?: MobileNetMultiplier;\n  modelUrl?: string;\n  quantBytes?: PoseNetQuantBytes;\n}\n\n// The default configuration for loading MobileNetV1 based PoseNet.\n//\n// (And for references, the default configuration for loading ResNet\n// based PoseNet is also included).\n//\n// ```\n// const RESNET_CONFIG = {\n//   architecture: 'ResNet50',\n//   outputStride: 32,\n//   quantBytes: 2,\n// } as ModelConfig;\n// ```\nconst MOBILENET_V1_CONFIG: ModelConfig = {\n  architecture: 'MobileNetV1',\n  outputStride: 16,\n  multiplier: 0.75,\n  inputResolution: 257,\n} as ModelConfig;\n\nconst VALID_ARCHITECTURE = ['MobileNetV1', 'ResNet50'];\nconst VALID_STRIDE = {\n  'MobileNetV1': [8, 16, 32],\n  'ResNet50': [32, 16]\n};\n\nconst VALID_MULTIPLIER = {\n  'MobileNetV1': [0.50, 0.75, 1.0],\n  'ResNet50': [1.0]\n};\nconst VALID_QUANT_BYTES = [1, 2, 4];\n\nfunction validateModelConfig(config: ModelConfig) {\n  config = config || MOBILENET_V1_CONFIG;\n\n  if (config.architecture == null) {\n    config.architecture = 'MobileNetV1';\n  }\n  if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\n    throw new Error(\n        `Invalid architecture ${config.architecture}. ` +\n        `Should be one of ${VALID_ARCHITECTURE}`);\n  }\n\n  if (config.inputResolution == null) {\n    config.inputResolution = 257;\n  }\n\n  validateInputResolution(config.inputResolution);\n\n  if (config.outputStride == null) {\n    config.outputStride = 16;\n  }\n  if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\n    throw new Error(\n        `Invalid outputStride ${config.outputStride}. ` +\n        `Should be one of ${VALID_STRIDE[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.multiplier == null) {\n    config.multiplier = 1.0;\n  }\n  if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\n    throw new Error(\n        `Invalid multiplier ${config.multiplier}. ` +\n        `Should be one of ${VALID_MULTIPLIER[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.quantBytes == null) {\n    config.quantBytes = 4;\n  }\n  if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\n    throw new Error(\n        `Invalid quantBytes ${config.quantBytes}. ` +\n        `Should be one of ${VALID_QUANT_BYTES} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.architecture === 'MobileNetV1' && config.outputStride === 32 &&\n      config.multiplier !== 1) {\n    throw new Error(\n        `When using an output stride of 32, ` +\n        `you must select 1 as the multiplier.`);\n  }\n\n  return config;\n}\n\n/**\n * PoseNet inference is configurable using the following config dictionary.\n *\n * `flipHorizontal`: If the poses should be flipped/mirrored horizontally.\n * This should be set to true for videos where the video is by default flipped\n * horizontally (i.e. a webcam), and you want the poses to be returned in the\n * proper orientation.\n *\n */\nexport interface InferenceConfig {\n  flipHorizontal: boolean;\n}\n\n/**\n * Single Person Inference Config\n */\nexport interface SinglePersonInterfaceConfig extends InferenceConfig {}\n\n/**\n * Multiple Person Inference Config\n *\n * `maxDetections`: Maximum number of returned instance detections per image.\n *\n * `scoreThreshold`: Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5\n *\n * `nmsRadius`: Non-maximum suppression part distance in pixels. It needs\n * to be strictly positive. Two parts suppress each other if they are less\n * than `nmsRadius` pixels away. Defaults to 20.\n */\nexport interface MultiPersonInferenceConfig extends InferenceConfig {\n  maxDetections?: number;\n  scoreThreshold?: number;\n  nmsRadius?: number;\n}\n\n// these added back to not break the existing api.\nexport interface LegacyMultiPersonInferenceConfig extends\n    MultiPersonInferenceConfig {\n  decodingMethod: 'multi-person';\n}\n\nexport interface LegacySinglePersonInferenceConfig extends\n    SinglePersonInterfaceConfig {\n  decodingMethod: 'single-person';\n}\n\nexport const SINGLE_PERSON_INFERENCE_CONFIG: SinglePersonInterfaceConfig = {\n  flipHorizontal: false\n};\n\nexport const MULTI_PERSON_INFERENCE_CONFIG: MultiPersonInferenceConfig = {\n  flipHorizontal: false,\n  maxDetections: 5,\n  scoreThreshold: 0.5,\n  nmsRadius: 20\n};\n\nfunction validateSinglePersonInferenceConfig(\n    config: SinglePersonInterfaceConfig) {}\n\nfunction validateMultiPersonInputConfig(config: MultiPersonInferenceConfig) {\n  const {maxDetections, scoreThreshold, nmsRadius} = config;\n\n  if (maxDetections <= 0) {\n    throw new Error(\n        `Invalid maxDetections ${maxDetections}. ` +\n        `Should be > 0`);\n  }\n\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n    throw new Error(\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (nmsRadius <= 0) {\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\n  }\n}\n\nexport class PoseNet {\n  readonly baseModel: BaseModel;\n  readonly inputResolution: [number, number];\n\n  constructor(net: BaseModel, inputResolution: [number, number]) {\n    assertValidOutputStride(net.outputStride);\n    assertValidResolution(inputResolution, net.outputStride);\n\n    this.baseModel = net;\n    this.inputResolution = inputResolution;\n  }\n\n  /**\n   * Infer through PoseNet, and estimates multiple poses using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns up to\n   * `config.maxDetections` object instance detections in decreasing root\n   * score order.\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config MultiPoseEstimationConfig object that contains parameters\n   * for the PoseNet inference using multiple pose estimation.\n   *\n   * @return An array of poses and their scores, each containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateMultiplePoses(\n      input: PosenetInput,\n      config: MultiPersonInferenceConfig = MULTI_PERSON_INFERENCE_CONFIG):\n      Promise<Pose[]> {\n    const configWithDefaults: MultiPersonInferenceConfig = {\n      ...MULTI_PERSON_INFERENCE_CONFIG,\n      ...config\n    };\n\n    validateMultiPersonInputConfig(config);\n\n    const outputStride = this.baseModel.outputStride;\n    const inputResolution = this.inputResolution;\n\n    const [height, width] = getInputTensorDimensions(input);\n\n    const {resized, padding} = padAndResizeTo(input, inputResolution);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        this.baseModel.predict(resized);\n\n    const allTensorBuffers = await toTensorBuffers3D(\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\n\n    const scoresBuffer = allTensorBuffers[0];\n    const offsetsBuffer = allTensorBuffers[1];\n    const displacementsFwdBuffer = allTensorBuffers[2];\n    const displacementsBwdBuffer = allTensorBuffers[3];\n\n    const poses = await decodeMultiplePoses(\n        scoresBuffer, offsetsBuffer, displacementsFwdBuffer,\n        displacementsBwdBuffer, outputStride, configWithDefaults.maxDetections,\n        configWithDefaults.scoreThreshold, configWithDefaults.nmsRadius);\n\n    const resultPoses = scaleAndFlipPoses(\n        poses, [height, width], inputResolution, padding,\n        configWithDefaults.flipHorizontal);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n    resized.dispose();\n\n    return resultPoses;\n  }\n\n  /**\n   * Infer through PoseNet, and estimates a single pose using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns a single pose\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config SinglePersonEstimationConfig object that contains\n   * parameters for the PoseNet inference using single pose estimation.\n   *\n   * @return An pose and its scores, containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateSinglePose(\n      input: PosenetInput,\n      config: SinglePersonInterfaceConfig = SINGLE_PERSON_INFERENCE_CONFIG):\n      Promise<Pose> {\n    const configWithDefaults = {...SINGLE_PERSON_INFERENCE_CONFIG, ...config};\n\n    validateSinglePersonInferenceConfig(configWithDefaults);\n\n    const outputStride = this.baseModel.outputStride;\n    const inputResolution = this.inputResolution;\n\n    const [height, width] = getInputTensorDimensions(input);\n\n    const {resized, padding} = padAndResizeTo(input, inputResolution);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        this.baseModel.predict(resized);\n\n    const pose = await decodeSinglePose(heatmapScores, offsets, outputStride);\n    const poses = [pose];\n\n    const resultPoses = scaleAndFlipPoses(\n        poses, [height, width], inputResolution, padding,\n        configWithDefaults.flipHorizontal);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n    resized.dispose();\n\n    return resultPoses[0];\n  }\n\n  /** Deprecated: Use either estimateSinglePose or estimateMultiplePoses */\n  async estimatePoses(\n      input: PosenetInput,\n      config: LegacySinglePersonInferenceConfig|\n      LegacyMultiPersonInferenceConfig): Promise<Pose[]> {\n    if (config.decodingMethod === 'single-person') {\n      const pose = await this.estimateSinglePose(input, config);\n      return [pose];\n    } else {\n      return this.estimateMultiplePoses(input, config);\n    }\n  }\n\n  public dispose() {\n    this.baseModel.dispose();\n  }\n}\n\nasync function loadMobileNet(config: ModelConfig): Promise<PoseNet> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  const multiplier = config.multiplier;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = mobileNetCheckpoint(outputStride, multiplier, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const mobilenet = new MobileNet(graphModel, outputStride);\n\n  const validInputResolution = getValidInputResolutionDimensions(\n      config.inputResolution, mobilenet.outputStride);\n\n  return new PoseNet(mobilenet, validInputResolution);\n}\n\nasync function loadResNet(config: ModelConfig): Promise<PoseNet> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = resNet50Checkpoint(outputStride, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const resnet = new ResNet(graphModel, outputStride);\n  const validInputResolution = getValidInputResolutionDimensions(\n      config.inputResolution, resnet.outputStride);\n  return new PoseNet(resnet, validInputResolution);\n}\n\n/**\n * Loads the PoseNet model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the PoseNet loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nexport async function load(config: ModelConfig = MOBILENET_V1_CONFIG):\n    Promise<PoseNet> {\n  config = validateModelConfig(config);\n  if (config.architecture === 'ResNet50') {\n    return loadResNet(config);\n  } else if (config.architecture === 'MobileNetV1') {\n    return loadMobileNet(config);\n  } else {\n    return null;\n  }\n}\n", "/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.2.2';\nexport {version};\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BA,IAAA,YAAA,WAAA;AACE,WAAA,EACuBA,IACHC,GAAAA;AADGC,SAAAA,QAAAF,IACHE,KAAAA,eAAAD;AAClB,QAAME,IACFD,KAAKF,MAAMI,OAAO,CAAA,EAAGC;AACzBC,iBAAQC,OAAAA,OACHJ,EAAW,CAAA,KAAA,OAAeA,EAAW,CAAA,GACtC,WAAA;AAAM,aAAA,kBAAgBA,EAAW,CAAA,IAAA,OAAOA,EAAW,CAAA,IAAA;IAAA,CAAA;EAAA;AAyD3D,SAtCEK,EAAAA,UAAAA,UAAA,SAAQC,IAAAA;AAAR,QAAA,IAAA;AAME,WAAOC,KAAQ,WAAA;AACb,UAAMC,IAAUC,EAAKC,gBAAgBC,KAAQL,IAAO,SAAA,CAAA,GAC9CM,IAAUC,WAAcL,GAAS,CAAA,GAEjCM,IADUL,EAAKZ,MAAMkB,QAAQH,CAAAA,EACMI,IAAI,SAAAC,IAAAA;AAAK,eAAAC,QAAWD,IAAAA,CAAI,CAAA,CAAA;MAAA,CAAA,GAE3DE,IAAeV,EAAKW,kBAAkBN,CAAAA;AAE5C,aAAA,EACEO,eAAeC,QAAWH,EAAaI,OAAAA,GACvCC,SAASL,EAAaK,SACtBC,iBAAiBN,EAAaM,iBAC9BC,iBAAiBP,EAAaO,gBAAAA;IAAAA,CAAAA;EAAAA,GAiBpCrB,EAAAA,UAAAA,UAAA,WAAA;AACEN,SAAKF,MAAM8B,QAAAA;EAAAA,GAAAA;AAAAA,EAAAA;AA/Df,IA+DeA,YAAAA,SAAAA,GAAAA;ACzEf,WAAA,IAAA;AAAA,WAAA,SAAA,KAAA,EAAA,MAAA,MAAA,SAAA,KAAA;EAAA;AAUA,SAV+BC,UAAAA,GAAAA,CAAAA,GAC7BC,EAAAA,UAAAA,kBAAA,SAAgBvB,IAAAA;AAEd,WAAOC,KAAQ,WAAA;AAAM,aAAAuB,IAAOC,IAAOzB,IAAO,KAAA,GAAQ,CAAA;IAAA,CAAA;EAAA,GAGpDuB,EAAAA,UAAAA,oBAAA,SAAkBG,IAAAA;AAEhB,WAAA,EAAQR,SAAAA,GAAAA,CAAAA,GAASD,SAAAA,GAAAA,CAAAA,GAASE,iBAAAA,GAAAA,CAAAA,GAAiBC,iBAAAA,GAAAA,CAAAA,EAAAA;EAAAA,GAAAA;AAAAA,EARhBrB,SAAAA;ACA/B,SAAS4B,KAAKC,GAAAA;AACZ,SAAOC,KAAKC,MAAMF,IAAI,CAAA;AAAA;AAGxB,IAAA,UAAA,WAAA;AAKE,WAAA,EAAYG,IAAiBC,GAAAA;AAC3BvC,SAAKwC,gBAAgB,IAAIC,MAAMH,EAAAA,GAC/BtC,KAAK0C,mBAAAA,IACL1C,KAAKuC,kBAAkBA;EAAAA;AAkE3B,SA/DSI,EAAAA,UAAAA,UAAP,SAAeC,IAAAA;AACb5C,SAAKwC,cAAAA,EAAgBxC,KAAK0C,gBAAAA,IAAoBE,IAC9C5C,KAAK6C,KAAK7C,KAAK0C,gBAAAA;EAAAA,GAGVC,EAAAA,UAAAA,UAAP,WAAA;AACE,QAAMG,KAAM9C,KAAKwC,cAAc,CAAA;AAI/B,WAHAxC,KAAK+C,SAAS,GAAG/C,KAAK0C,kBAAAA,GACtB1C,KAAKgD,KAAK,CAAA,GACVhD,KAAKwC,cAAcxC,KAAK0C,mBAAmB,CAAA,IAAK,MACzCI;EAAAA,GAGFH,EAAAA,UAAAA,QAAP,WAAA;AACE,WAAA,OAAO3C,KAAK0C;EAAAA,GAGPC,EAAAA,UAAAA,OAAP,WAAA;AACE,WAAO3C,KAAK0C,mBAAmB;EAAA,GAG1BC,EAAAA,UAAAA,MAAP,WAAA;AACE,WAAO3C,KAAKwC,cAAcS,MAAM,GAAGjD,KAAK0C,mBAAmB,CAAA;EAAA,GAGtDC,EAAAA,UAAAA,MAAP,WAAA;AACE,WAAO3C,KAAKwC,cAAc,CAAA;EAAA,GAGpBG,EAAAA,UAAAA,OAAR,SAAaR,IAAAA;AACX,WAAOA,KAAI,KAAKnC,KAAKkD,KAAKhB,KAAKC,EAAAA,GAAIA,EAAAA,IACjCnC,MAAK+C,SAASZ,IAAGD,KAAKC,EAAAA,CAAAA,GACtBA,KAAID,KAAKC,EAAAA;EAAAA,GAILQ,EAAAA,UAAAA,OAAR,SAAaR,IAAAA;AACX,WAAO,IAAIA,MAAKnC,KAAK0C,oBAAkB;AACrC,UAAIS,IAAI,IAAIhB;AAIZ,UAHIgB,IAAInD,KAAK0C,oBAAoB1C,KAAKkD,KAAKC,GAAGA,IAAI,CAAA,KAChDA,KAAAA,CAEGnD,KAAKkD,KAAKf,IAAGgB,CAAAA,EAChB;AAEFnD,WAAK+C,SAASZ,IAAGgB,CAAAA,GACjBhB,KAAIgB;IAAAA;EAAAA,GAIAR,EAAAA,UAAAA,aAAR,SAAmBS,IAAAA;AACjB,WAAOpD,KAAKuC,gBAAgBvC,KAAKwC,cAAcY,EAAAA,CAAAA;EAAAA,GAGzCT,EAAAA,UAAAA,OAAR,SAAaS,IAAWD,GAAAA;AACtB,WAAOnD,KAAKqD,WAAWD,EAAAA,IAAKpD,KAAKqD,WAAWF,CAAAA;EAAAA,GAGtCR,EAAAA,UAAAA,WAAR,SAAiBS,IAAWD,GAAAA;AAC1B,QAAMG,IAAItD,KAAKwC,cAAcY,EAAAA;AAC7BpD,SAAKwC,cAAcY,EAAAA,IAAKpD,KAAKwC,cAAcW,CAAAA,GAC3CnD,KAAKwC,cAAcW,CAAAA,IAAKG;EAAAA,GAAAA;AAAAA,EAAAA;AC7E5B,SAESC,4BACLC,GAAoBC,GAAeC,GAAkBC,GACrDC,GAA4BC,GAAAA;AAM9B,WALMC,IAAAA,EAAAA,OAACC,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GAEXC,IAAAA,MACEC,IAAS9B,KAAKU,IAAIY,IAAWE,GAAoB,CAAA,GACjDO,IAAO/B,KAAKgC,IAAIV,IAAWE,IAAqB,GAAGG,CAAAA,GAChDM,IAAWH,GAAQG,IAAWF,GAAAA,EAAQE,GAAU;AAGvD,aAFMC,IAASlC,KAAKU,IAAIa,IAAWC,GAAoB,CAAA,GACjDW,IAAOnC,KAAKgC,IAAIT,IAAWC,IAAqB,GAAGI,CAAAA,GAChDQ,IAAWF,GAAQE,IAAWD,GAAAA,EAAQC,EAC7C,KAAIX,EAAOY,IAAIJ,GAAUG,GAAUhB,CAAAA,IAAcC,GAAO;AACtDQ,UAAAA;AACA;IAAA;AAGJ,QAAA,CAAKA,EACH;EAAA;AAIJ,SAAOA;AAAAA;AAQT,SAAgBS,wBACZC,GAAwBf,GACxBC,GAAAA;AAMF,WALMC,IAAAA,EAAAA,OAACC,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GAAOY,IAAAA,EAAAA,CAAAA,GAEhBC,IAAQ,IAAIlC,QACdoB,IAASC,IAAQY,GAAc,SAACd,IAAAA;AAAY,WAAAgB,GAAA;EAAA,CAAA,GAEvCpB,IAAW,GAAGA,IAAWK,GAAAA,EAAUL,EAC1C,UAASC,IAAW,GAAGA,IAAWK,GAAAA,EAASL,EACzC,UAASH,IAAa,GAAGA,IAAaoB,GAAAA,EAAgBpB,GAAY;AAChE,QAAMC,IAAQI,EAAOY,IAAIf,GAAUC,GAAUH,CAAAA;AAIzCC,QAAQkB,KAKRpB,4BACIC,GAAYC,GAAOC,GAAUC,GAAUC,GACvCC,CAAAA,KACNgB,EAAME,QAAAA,EAAStB,OAAAA,GAAOuB,MAAAA,EAAOtB,UAAAA,GAAUC,UAAAA,GAAUsB,IAAIzB,EAAAA,EAAAA,CAAAA;EAAAA;AAM7D,SAAOqB;AAAAA;AC3DT,IAAaK,YAAAA,CACX,QAAQ,WAAW,YAAY,WAAW,YAAY,gBACtD,iBAAiB,aAAa,cAAc,aAAa,cACzD,WAAW,YAAY,YAAY,aAAa,aAAa,YAAA;AAH/D,IAMaC,gBAAgBD,UAAUE;AANvC,IAYaC,UACTH,UAAUI,OAAO,SAACC,GAAoBC,GAAWpC,GAAAA;AAE/C,SADAmC,EAAOC,CAAAA,IAAapC,GACbmC;AAAAA,GAAAA,CAAAA,CAAAA;AAfb,IAkBME,qBAAAA,CAAAA,CACH,WAAW,cAAA,GAAA,CAAkB,aAAa,cAAA,GAAA,CAC1C,aAAa,WAAA,GAAA,CAAe,WAAW,UAAA,GAAA,CACvC,YAAY,WAAA,GAAA,CAAe,YAAY,eAAA,GAAA,CACvC,cAAc,eAAA,GAAA,CAAmB,cAAc,YAAA,GAAA,CAC/C,YAAY,WAAA,GAAA,CAAe,aAAa,YAAA,GAAA,CACxC,gBAAgB,eAAA,GAAA,CAAmB,WAAW,UAAA,CAAA;AAxBjD,IAiCaC,YAAAA,CAAAA,CACV,QAAQ,SAAA,GAAA,CAAa,WAAW,SAAA,GAAA,CAAa,QAAQ,UAAA,GAAA,CACrD,YAAY,UAAA,GAAA,CAAc,QAAQ,cAAA,GAAA,CAClC,gBAAgB,WAAA,GAAA,CAAe,aAAa,WAAA,GAAA,CAC5C,gBAAgB,SAAA,GAAA,CAAa,WAAW,UAAA,GAAA,CACxC,YAAY,WAAA,GAAA,CAAe,QAAQ,eAAA,GAAA,CACnC,iBAAiB,YAAA,GAAA,CAAgB,cAAc,YAAA,GAAA,CAC/C,iBAAiB,UAAA,GAAA,CAAc,YAAY,WAAA,GAAA,CAC3C,aAAa,YAAA,CAAA;AAzChB,IA4CaC,uBAAuBF,mBAAmBxE,IACnD,SAAC6C,GAAAA;AAAAA,MAAC8B,IAAAA,EAAAA,CAAAA,GAAYC,IAAAA,EAAAA,CAAAA;AAAgB,SAAA,CAAER,QAAQO,CAAAA,GAAaP,QAAQQ,CAAAA,CAAAA;AAAAA,CAAAA;AA7CjE,IA+CaC,eAAAA,CACX,aACA,cACA,yBACA,wBACA,wBACA,wBACA,wBACA,uBACA,uBACA,cACA,yBACA,aACA,eACA,cACA,yBACA,wBACA,wBACA,wBACA,wBACA,uBACA,uBACA,cACA,yBACA,WAAA;AC3EF,SAGgBC,eACZ7E,GAAW0B,GAAWoD,GAAkBvE,GAAAA;AAC1C,SAAA,EACEP,GAAGO,EAAQgD,IAAIvD,GAAG0B,GAAGoD,CAAAA,GACrBpD,GAAGnB,EAAQgD,IAAIvD,GAAG0B,GAAGoD,IAAWb,aAAAA,EAAAA;AAAAA;AAIpC,SAAgBc,eACZjB,GAAYjF,GAAsB0B,GAAAA;AAC7B,MACDqC,IAAAA,eAAAA,EAAAA,UAAAA,EAAAA,UAAAA,EAAAA,IAAAA,CAAAA,GAAC5C,IAAAA,EAAAA,GAAG0B,IAAAA,EAAAA;AACV,SAAA,EACEA,GAAGoC,EAAKrB,WAAW5D,IAAe6C,GAClC1B,GAAG8D,EAAKtB,WAAW3D,IAAemB,EAAAA;AAAAA;AAItC,SAUgBgF,MAAMC,GAAW/B,GAAatB,GAAAA;AAC5C,SAAIqD,IAAI/B,IACCA,IAEL+B,IAAIrD,IACCA,IAEFqD;AAAAA;AAGT,SAAgBC,gBACZC,GAAYC,GAAYC,GAAYC,GAAAA;AACtC,MAAMC,IAAKF,IAAKF,GACVK,IAAKF,IAAKF;AAChB,SAAOG,IAAKA,IAAKC,IAAKA;AAAAA;AAGxB,SAAgBC,WAAWR,GAAaS,GAAAA;AACtC,SAAA,EAAQhE,GAAGuD,EAAEvD,IAAIgE,EAAEhE,GAAG1B,GAAGiF,EAAEjF,IAAI0F,EAAE1F,EAAAA;AAAAA;ACjDnC,IAMM2F,uBAAsCnB,UAAUzE,IAClD,SAAC6C,GAAAA;AAAAA,MAACgD,IAAAA,EAAAA,CAAAA,GAAgBC,IAAAA,EAAAA,CAAAA;AACd,SAAA,CAAE1B,QAAQyB,CAAAA,GAAiBzB,QAAQ0B,CAAAA,CAAAA;AAAAA,CAAAA;AAR3C,IAUMC,qBACFH,qBAAqB5F,IAAI,SAAC6C,GAAAA;AAAqB,SAAA,EAAA,CAAA;AAAA,CAAA;AAXnD,IAaMmD,qBACFJ,qBAAqB5F,IAAI,SAAC6C,GAAAA;AAEK,SAAA,EAAA,CAAA;AAAA,CAAA;AAEnC,SAASoD,gBACLC,GAAgBC,GAAiBC,GAAAA;AACnC,MAAMC,IAAWD,EAAclH,MAAM,CAAA,IAAK;AAC1C,SAAA,EACEe,GAAGmG,EAAc5C,IAAI2C,EAAMlG,GAAGkG,EAAMxE,GAAGuE,CAAAA,GACvCvE,GAAGyE,EAAc5C,IAAI2C,EAAMlG,GAAGkG,EAAMxE,GAAG0E,IAAWH,CAAAA,EAAAA;AAAAA;AAItD,SAASI,yBACLH,GAAiBrH,GAAsBgE,GACvCC,GAAAA;AACF,SAAA,EACE9C,GAAGgF,MAAM9D,KAAKoF,MAAMJ,EAAMlG,IAAInB,CAAAA,GAAe,GAAGgE,IAAS,CAAA,GACzDnB,GAAGsD,MAAM9D,KAAKoF,MAAMJ,EAAMxE,IAAI7C,CAAAA,GAAe,GAAGiE,IAAQ,CAAA,EAAA;AAAA;AAW5D,SAASyD,yBACLN,GAAgBO,GAA0BC,GAC1CC,GAA8BnG,GAAyB1B,GACvDsH,GAA+BQ,GAAAA;AAAAA,aAAAA,MAAAA,IAAAA;AAYjC,WAXM/D,IAAAA,EAAAA,OAACC,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GAMT8D,IACFZ,gBAAgBC,GAJUI,yBAC1BG,EAAeK,UAAUhI,GAAcgE,GAAQC,CAAAA,GAGAqD,CAAAA,GAG/CW,IADmBrB,WAAWe,EAAeK,UAAUD,CAAAA,GAElD1E,IAAI,GAAGA,IAAIyE,GAAkBzE,KAAK;AACzC,QAAM6E,IACFV,yBAAyBS,GAAgBjI,GAAcgE,GAAQC,CAAAA,GAE7DkE,IAAcnC,eAChBkC,EAAsB/G,GAAG+G,EAAsBrF,GAAG+E,GAClDlG,CAAAA;AAEJuG,QAAiBrB,WAAAA,EAEX/D,GAAGqF,EAAsBrF,IAAI7C,GAC7BmB,GAAG+G,EAAsB/G,IAAInB,EAAAA,GAAAA,EAE9B6C,GAAGsF,EAAYtF,GAAG1B,GAAGgH,EAAYhH,EAAAA,CAAAA;EAAAA;AAExC,MAAMiH,IACFZ,yBAAyBS,GAAgBjI,GAAcgE,GAAQC,CAAAA,GAC7DP,IAAQmE,EAAanD,IACvB0D,EAAsBjH,GAAGiH,EAAsBvF,GAAG+E,CAAAA;AAEtD,SAAA,EAAQI,UAAUC,GAAgBhD,MAAME,UAAUyC,CAAAA,GAAmBlE,OAAAA,EAAAA;AAAAA;AASvE,SAAgB2E,WACZC,GAAqBxE,GAAwBpC,GAC7C1B,GAAsBuI,GACtBC,GAAAA;AACF,MAAMC,IAAW3E,EAAO1D,MAAM,CAAA,GACxBmH,IAAWN,mBAAmB5B,QAE9BqD,IAAgC,IAAIhG,MAAM+F,CAAAA,GAEzCE,IAAAA,EAAAA,MAAgBC,IAAAA,EAAAA,OACjBC,IAAY3C,eAAeyC,GAAU3I,GAAc0B,CAAAA;AAEzDgH,IAAkBC,EAASzD,EAAAA,IAAAA,EACzBxB,OAAOkF,GACP3D,MAAME,UAAUwD,EAASzD,EAAAA,GACzB8C,UAAUa,EAAAA;AAKZ,WAASC,IAAOvB,IAAW,GAAGuB,KAAQ,GAAA,EAAKA,GAAM;AAC/C,QAAMC,IAAmB9B,mBAAmB6B,CAAAA,GACtClB,IAAmBV,mBAAmB4B,CAAAA;AACxCJ,MAAkBK,CAAAA,KAAAA,CACjBL,EAAkBd,CAAAA,MACrBc,EAAkBd,CAAAA,IAAoBF,yBAClCoB,GAAMJ,EAAkBK,CAAAA,GAAmBnB,GAAkB9D,GAC7DpC,GAAS1B,GAAcwI,CAAAA;EAAAA;AAM/B,OAASM,IAAO,GAAGA,IAAOvB,GAAAA,EAAYuB,GAAM;AACpCC,QAAmB7B,mBAAmB4B,CAAAA,GACtClB,IAAmBX,mBAAmB6B,CAAAA;AACxCJ,MAAkBK,CAAAA,KAAAA,CACjBL,EAAkBd,CAAAA,MACrBc,EAAkBd,CAAAA,IAAoBF,yBAClCoB,GAAMJ,EAAkBK,CAAAA,GAAmBnB,GAAkB9D,GAC7DpC,GAAS1B,GAAcuI,CAAAA;EAAAA;AAI/B,SAAOG;AAAAA;ACjIT,SAISM,oCACLC,GAAeC,GAA0BnF,GACzCN,GAAAA;AAAAA,MAD0CZ,IAAAA,EAAAA,GAAG1B,IAAAA,EAAAA;AAE/C,SAAO8H,EAAME,KAAK,SAACpF,IAAAA;AAAAA,QACXqF,KAAAA,GAAAA,UAAkC3F,CAAAA,EAAYuE;AACpD,WAAO3B,gBACIlF,GAAG0B,GAAGuG,GAAsBjI,GAAGiI,GAAsBvG,CAAAA,KAC5DqG;EAAAA,CAAAA;AAAAA;AAQR,SAASG,iBACLC,GAAuBJ,GACvBR,GAAAA;AAUF,SATkCA,EAAkBnD,OAChD,SAACC,IAAQzB,GAAmBN,GAAAA;AAAAA,QAAlBuE,IAAAA,EAAAA,UAAUtE,IAAAA,EAAAA;AAKlB,WAJKsF,oCACGM,GAAeJ,GAAkBlB,GAAUvE,CAAAA,MACjD+B,MAAU9B,IAEL8B;EAAAA,GACN,CAAA,IAE+BkD,EAAkBrD;AAAAA;AAM1D,IAAMkE,sBAAsB;AAyD5B,SAAgBC,oBACZ3B,GAA8B4B,GAC9BC,GACAC,GAAwC3J,GACxC4J,GAA2BhF,GAAsBiF,GAAAA;AAAAA,aAAAA,MAAtBjF,IAAAA,MAAAA,WAAAA,MAAsBiF,IAAAA;AAUnD,WATMZ,IAAAA,CAAAA,GAEAnE,IAAQH,wBACVC,GAAgB2E,qBAAqB1B,CAAAA,GAEnCqB,IAAmBW,IAAYA,GAI9BZ,EAAM5D,SAASuE,KAAAA,CAAsB9E,EAAMgF,MAAAA,KAAS;AAEzD,QAAMxB,IAAOxD,EAAMiF,QAAAA;AAOnB,QAAA,CAAIf,oCACIC,GAAOC,GAFXhD,eAAeoC,EAAKrD,MAAMjF,GAAcyJ,CAAAA,GAEMnB,EAAKrD,KAAKC,EAAAA,GAD5D;AAMA,UAAM8E,IAAY3B,WACdC,GAAMT,GAAc4B,GAAezJ,GAAc0J,GACjDC,CAAAA,GAEEjG,IAAQ2F,iBAAiBJ,GAAOC,GAAkBc,CAAAA;AAExDf,QAAMgB,KAAAA,EAAMD,WAAAA,GAAWtG,OAAAA,EAAAA,CAAAA;IAAAA;EAAAA;AAGzB,SAAOuF;AAAAA;ACtIT,SAESiB,IAAI9D,GAAgBS,GAAAA;AAC3B,SAAOpG,KAAQ,WAAA;AACb,QAAM0J,IAAUlI,IAAOmE,GAAGgE,OAAUvD,GAAG,OAAA,CAAA;AAEvC,WAAO7E,IAAOoE,GAAGiE,IAAOF,GAASC,OAAUvD,GAAG,OAAA,CAAA,CAAA;EAAA,CAAA;AAAA;AAIlD,SAAgByD,SAASnK,GAAAA;AACjB,MAAA4D,IAAAA,EAAAA,OAACC,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GAAOsG,IAAAA,EAAAA,CAAAA;AAEtB,SAAO9J,KAAQ,WAAA;AACb,QAAM+J,KAAWC,QAAWtK,GAAAA,CAAS6D,IAASC,GAAOsG,CAAAA,CAAAA,GAC/CG,IAASC,OAAUH,IAAU,CAAA,GAE7BI,IAAU7J,WAAckB,IAAOyI,GAAQN,OAAUnG,GAAO,OAAA,CAAA,GAAW,CAAA,GACnE4G,IAAU9J,WAAcmJ,IAAIQ,GAAuBzG,CAAAA,GAAQ,CAAA;AAEjE,WAAO6G,OAAAA,CAAWF,GAASC,CAAAA,GAAU,CAAA;EAAA,CAAA;AAAA;ACpBzC,SAIgBE,oBACZxJ,GACAyJ,GAAAA;AAIF,WAHMnG,IAAemG,EAAc5K,MAAM,CAAA,GACnCoF,IAAS,IAAIyF,aAAapG,CAAAA,GAEvBoB,IAAW,GAAGA,IAAWpB,GAAcoB,KAAY;AAC1D,QAAM9E,IAAI6J,EAActG,IAAIuB,GAAU,CAAA,GAChCpD,IAAImI,EAActG,IAAIuB,GAAU,CAAA;AACtCT,MAAOS,CAAAA,IAAY1E,EAAcmD,IAAIvD,GAAG0B,GAAGoD,CAAAA;EAAAA;AAG7C,SAAOT;AAAAA;AAGT,SAASQ,iBACL7E,GAAW0B,GAAWoD,GACtBwD,GAAAA;AACF,SAAA,EACEtI,GAAGsI,EAAc/E,IAAIvD,GAAG0B,GAAGoD,CAAAA,GAC3BpD,GAAG4G,EAAc/E,IAAIvD,GAAG0B,GAAGoD,IAAWb,aAAAA,EAAAA;AAAAA;AAI1C,SAAgB8F,iBACZC,GACA1B,GAAAA;AAGF,WAFMjE,IAAAA,CAAAA,GAEGS,IAAW,GAAGA,IAAWb,eAAea,KAAY;AAC3D,QAGMlC,IAAAA,iBAHWoH,EAAoBzG,IAAIuB,GAAU,CAAA,EAAGmF,QAAAA,GACrCD,EAAoBzG,IAAIuB,GAAU,CAAA,EAAGmF,QAAAA,GAAAA,GAAAA,CAAAA,GAE/CvI,IAAAA,EAAAA,GAAG1B,IAAAA,EAAAA;AAEVqE,MAAOyE,KAAK9I,CAAAA,GACZqE,EAAOyE,KAAKpH,CAAAA;EAAAA;AAGd,SAAOwI,SAAY7F,GAAAA,CAASJ,eAAe,CAAA,CAAA;AAAA;AAG7C,SAAgBkG,gBACZH,GAAkDnL,GAClDyJ,GAAAA;AACF,SAAOhJ,KAAQ,WAAA;AACb,QAAM8K,IAAgBL,iBAAiBC,GAAqB1B,CAAAA;AAE5D,WAAO+B,IACEC,KACGC,IACCP,EAAoBQ,SAAAA,GAAYvB,OAAUpK,GAC7C,OAAA,CAAA,GAAW,SAAA,GAAYuL,CAAAA;EAAAA,CAAAA;AAAAA;ACjBrC,SAAsBK,iBAClBrK,GAA4BG,GAC5B1B,GAAAA;AAAAA,SAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,QAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA;AAAAA,WAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAAAA,cAAAA,EAAAA,OAAAA;QAAAA,KAAAA;AAKuB,iBAJrB6L,IAAa,GAEXC,IAAgBxB,SAAS/I,CAAAA,GAAAA,CAAAA,GAEAwK,QAAQC,IAAAA,CAClCzK,EAAc0K,OAAAA,GAAUvK,EAAQuK,OAAAA,GAAUH,EAAcG,OAAAA,CAAAA,CAAAA,CAAAA;QAAAA,KAAAA;AAQlC,iBATrBC,IAAmBnI,EAAAA,KAAAA,GAGnB8D,IAAeqE,EAAiB,CAAA,GAChCzC,IAAgByC,EAAiB,CAAA,GACjCC,IAAsBD,EAAiB,CAAA,GAAA,CAAA,IAEvCE,IACFd,gBAAgBa,GAAqBnM,GAAcyJ,CAAAA,GACTwC,OAAAA,CAAAA;QAAAA,KAAAA;AAoB9C,iBApBMI,IAAqBtI,EAAAA,KAAAA,GAErBuI,IACF5J,MAAM6J,KAAKxB,oBAAoBlD,GAAcsE,CAAAA,CAAAA,GAE3CnC,IAAYsC,EAAmBpL,IAAI,SAACwC,IAAOD,IAAAA;AAE/C,mBADAoI,KAAcnI,IAAAA,EAEZsE,UAAAA,EACE7G,GAAGkL,EAAmB3H,IAAIjB,IAAY,CAAA,GACtCZ,GAAGwJ,EAAmB3H,IAAIjB,IAAY,CAAA,EAAA,GAExCwB,MAAME,UAAU1B,EAAAA,GAChBC,OAAAA,GAAAA;UAAAA,CAAAA,GAIJoI,EAAcjK,QAAAA,GACduK,EAAavK,QAAAA,GAAAA,CAAAA,GAAAA,EAELmI,WAAAA,GAAWtG,OAAOmI,IAAa7B,EAAU3E,OAAAA,CAAAA;MAAAA;IAAAA,CAAAA;EAAAA,CAAAA;AAAAA;AC3EnD,IAAMmH,qBACF;AADJ,IAEMC,oBACF;AAIJ,SAAgBC,mBAAmBC,GAAgBC,GAAAA;AACjD,MAAMC,IAAY,iBAAeF,IAAAA;AAEjC,SAAmB,MAAfC,IACKH,oBAAoB,WAAWI,IAE/BJ,oBAAoB,UAAQG,IAAAA,MAAgBC;AAAAA;AAMvD,SAAgBC,oBACZH,GAAgBI,GAAoBH,GAAAA;AACtC,MAAMI,IAAAA,EAAkCC,GAAK,OAAOC,MAAM,OAAOC,KAAM,MAAA,GACjEN,IAAY,iBAAeF,IAAAA;AAEjC,SAAmB,MAAfC,IACKJ,qBAAqB,WAASQ,EAAMD,CAAAA,IAAAA,MAAiBF,IAErDL,qBAAqB,UAAQI,IAAAA,MAAcI,EAAMD,CAAAA,IAAAA,MACpDF;AAAAA;AAAAA,ICxBFO,eAAAA,CAAAA,SAAiB,QAAS,OAAS;ADwBjCP,ICxBiC,SAAA,SAAA,GAAA;AAEzC,WAAA,IAAA;AAAA,WAAA,SAAA,KAAA,EAAA,MAAA,MAAA,SAAA,KAAA;EAAA;AASA,SAT4B/K,UAAAA,GAAAA,CAAAA,GAC1BuL,EAAAA,UAAAA,kBAAA,SAAgB7M,IAAAA;AACd,WAAO8M,IAAO9M,IAAO4M,YAAAA;EAAAA,GAGvBC,EAAAA,UAAAA,oBAAA,SAAkBnL,IAAAA;AACT,QAAAP,KAAAA,GAAAA,CAAAA,GAAiBC,IAAAA,GAAAA,CAAAA;AACxB,WAAA,EAAQF,SAAAA,GAAAA,CAAAA,GAASD,SAAAA,GAAAA,CAAAA,GAASE,iBAAAA,IAAiBC,iBAAAA,EAAAA;EAAAA,GAAAA;AAAAA,EAPnBrB,SAAAA;AAAAA,SCDnBgN,gCACLnH,GAAWS,GAAW2G,GAAAA;AACxB,SAAQpH,IAAIoH,KAAiB3G,IAAI2G;AAAAA;AAGnC,SAAgBC,qBACZzD,GAAuBwD,GAAAA;AACzB,SAAO5H,qBAAqBL,OACxB,SAACC,GAAsBzB,GAAAA;AAAAA,QAAC2J,IAAAA,EAAAA,CAAAA,GAAWC,IAAAA,EAAAA,CAAAA;AACjC,WAAIJ,gCACIvD,EAAU0D,CAAAA,EAAWhK,OAAOsG,EAAU2D,CAAAA,EAAYjK,OAClD8J,CAAAA,IACChI,KAGTA,EAAOyE,KAAAA,CAAMD,EAAU0D,CAAAA,GAAY1D,EAAU2D,CAAAA,CAAAA,CAAAA,GAEtCnI;EAAAA,GAAAA,CAAAA,CAAAA;AAAAA;AAIR,IAAAoI,oBAAAA,OAAAA;AAAA,IAAmBC,oBAAAA,OAAAA;AAC1B,SAAgBC,eAAe9D,GAAAA;AAE7B,SAAOA,EAAUzE,OAAO,SAACxB,IAA0BgK,GAAAA;AAAAA,QAAzBC,IAAAA,GAAAA,MAAMC,IAAAA,GAAAA,MAAMC,IAAAA,GAAAA,MAAMC,IAAAA,GAAAA,MAAQC,IAAAA,EAAAA,UAAWvL,IAAAA,EAAAA,GAAG1B,IAAAA,EAAAA;AAChE,WAAA,EACE6M,MAAM3L,KAAKU,IAAIiL,GAAMnL,CAAAA,GACrBoL,MAAM5L,KAAKU,IAAIkL,GAAM9M,CAAAA,GACrB+M,MAAM7L,KAAKgC,IAAI6J,GAAMrL,CAAAA,GACrBsL,MAAM9L,KAAKgC,IAAI8J,GAAMhN,CAAAA,EAAAA;EAAAA,GAAAA,EAGvB6M,MAAMJ,mBACNK,MAAML,mBACNM,MAAML,mBACNM,MAAMN,kBAAAA,CAAAA;AAAAA;AAIV,SAAgBQ,qBAAqBrE,GAAAA;AAC7B,MAAAjG,IAAAA,eAAAA,CAAAA,GAACmK,IAAAA,EAAAA,MAAMC,IAAAA,EAAAA,MAAMH,IAAAA,EAAAA,MAAMC,IAAAA,EAAAA;AACzB,SAAA,CAAA,EACGpL,GAAGqL,GAAM/M,GAAGgN,EAAAA,GAAAA,EAAQtL,GAAGmL,GAAM7M,GAAGgN,EAAAA,GAAAA,EAAQtL,GAAGmL,GAAM7M,GAAG8M,EAAAA,GAAAA,EACpDpL,GAAGqL,GAAM/M,GAAG8M,EAAAA,CAAAA;AAAAA;AAIjB,SAAsBK,kBAAkBC,GAAAA;AAAAA,SAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,WAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAEtC,aAAA,CAAA,GAAOxC,QAAQC,IAAIuC,EAAQrN,IAAI,SAAAsN,IAAAA;AAAU,eAAAA,GAAOvC,OAAAA;MAAAA,CAAAA,CAAAA,CAAAA;IAAAA,CAAAA;EAAAA,CAAAA;AAAAA;AAGlD,SAAgBwC,UACZC,GAAYC,GAAgBC,GAAgBC,GAC5CC,GAAAA;AACF,SAAA,WAAA,MAF8CD,IAAAA,IAAAA,WAAAA,MAC5CC,IAAAA,IAAAA,EAEApL,OAAOgL,EAAKhL,OACZsG,WAAW0E,EAAK1E,UAAU9I,IAAI,SAAC6C,IAAAA;AAAAA,QAACL,IAAAA,GAAAA,OAAOuB,IAAAA,GAAAA,MAAM+C,IAAAA,GAAAA;AAAc,WAAA,EAC3BtE,OAAAA,GACAuB,MAAAA,GACA+C,UAAAA,EACEnF,GAAGmF,EAASnF,IAAI+L,IAASE,GACzB3N,GAAG6G,EAAS7G,IAAIwN,IAASE,EAAAA,EAAAA;EAAAA,CAAAA,EAAAA;AAAAA;AAM/D,SAAgBE,WACZ9F,GAAe0F,GAAgBC,GAAgBC,GAAaC,GAAAA;AAC9D,SAAA,WAAA,MADiDD,IAAAA,IAAAA,WAAAA,MAAaC,IAAAA,IAC/C,MAAXF,KAA2B,MAAXD,KAA4B,MAAZE,KAA6B,MAAZC,IAC5C7F,IAEFA,EAAM/H,IAAI,SAAAwN,IAAAA;AAAQ,WAAAD,UAAUC,IAAMC,GAAQC,GAAQC,GAASC,CAAAA;EAAAA,CAAAA;AAAAA;AAGpE,SAAgBE,mBAAmBN,GAAYO,GAAAA;AAC7C,SAAA,EACEvL,OAAOgL,EAAKhL,OACZsG,WAAW0E,EAAK1E,UAAU9I,IACtB,SAAC6C,IAAAA;AAAAA,QAACL,IAAAA,GAAAA,OAAOuB,IAAAA,GAAAA,MAAM+C,IAAAA,GAAAA;AAAc,WAAA,EAC3BtE,OAAAA,GACAuB,MAAAA,GACA+C,UAAAA,EAAWnF,GAAGoM,IAAa,IAAIjH,EAASnF,GAAG1B,GAAG6G,EAAS7G,EAAAA,EAAAA;EAAAA,CAAAA,EAAAA;AAAAA;AAKjE,SAAgB+N,oBAAoBjG,GAAegG,GAAAA;AACjD,SAAIA,KAAc,IACThG,IAEFA,EAAM/H,IAAI,SAAAwN,IAAAA;AAAQ,WAAAM,mBAAmBN,IAAMO,CAAAA;EAAAA,CAAAA;AAAAA;AAGpD,SAAgBE,uBACZC,GAAyBpP,GAAAA;AAC3B,SAAIqP,uBAAuBD,GAAiBpP,CAAAA,IACnCoP,IAGF/M,KAAKC,MAAM8M,IAAkBpP,CAAAA,IAAgBA,IAAe;AAAA;AAGrE,SAAgBsP,wBAAwBF,GAAAA;AACtC/O,eAAQC,OACuB,YAAA,OAApB8O,KACwB,YAAA,OAApBA,GACX,WAAA;AAAM,WAAA,6BAA2BA,IAAAA;EAAAA,CAAAA,GAGN,YAAA,OAApBA,MACT/O,aAAQC,OAC6B,YAAA,OAA1B8O,EAAgBnL,OACvB,WAAA;AAAM,WAAA,0CACFmL,EAAgBnL,QAAAA;EAAAA,CAAAA,GACxB5D,aAAQC,OAC8B,YAAA,OAA3B8O,EAAgBpL,QACvB,WAAA;AAAM,WAAA,2CACFoL,EAAgBpL,SAAAA;EAAAA,CAAAA;AAAAA;AAI5B,SAAgBuL,kCACZH,GACApP,GAAAA;AAEF,SADAsP,wBAAwBF,CAAAA,GACO,YAAA,OAApBA,IAAAA,CAEPD,uBAAuBC,EAAgBpL,QAAQhE,CAAAA,GAC/CmP,uBAAuBC,EAAgBnL,OAAOjE,CAAAA,CAAAA,IAAAA,CAI9CmP,uBAAuBC,GAAiBpP,CAAAA,GACxCmP,uBAAuBC,GAAiBpP,CAAAA,CAAAA;AAAAA;AAK9C,IAAMwP,uBAAAA,CAA+C,GAAG,IAAI,EAAA;AAC5D,SAAgBC,wBAAwBzP,GAAAA;AACtCK,eAAQC,OACoB,YAAA,OAAjBN,GAA2B,WAAA;AAAM,WAAA;EAAA,CAAA,GAC5CK,aAAQC,OACJkP,qBAAqBE,QAAQ1P,CAAAA,KAAiB,GAC9C,WAAA;AAAM,WAAA,qBAAmBA,IAAAA;EAAAA,CAAAA;AAAAA;AAI/B,SAASqP,uBACLM,GAAoB3P,GAAAA;AACtB,UAAQ2P,IAAa,KAAK3P,KAAiB;AAAA;AAG7C,SAAgB4P,sBACZD,GAA8B3P,GAAAA;AAChCK,eAAQC,OACqB,YAAA,OAAlBqP,EAAW,CAAA,KAA4C,YAAA,OAAlBA,EAAW,CAAA,GACvD,WAAA;AAAM,WAAA,4DACFA;EAAAA,CAAAA,GAERtP,aAAQC,OACJ+O,uBAAuBM,EAAW,CAAA,GAAI3P,CAAAA,GACtC,WAAA;AAAM,WAAA,eAAa2P,EAAW,CAAA,IAAA,mCACvB3P,IAAAA;EAAAA,CAAAA,GAEXK,aAAQC,OACJ+O,uBAAuBM,EAAW,CAAA,GAAI3P,CAAAA,GACtC,WAAA;AAAM,WAAA,cAAY2P,EAAW,CAAA,IAAA,mCACtB3P,IAAAA;EAAAA,CAAAA;AAAAA;AAGb,SAAgB6P,yBAAyBrP,GAAAA;AAEvC,SAAOA,aAAiBsP,SAAAA,CAAatP,EAAMJ,MAAM,CAAA,GAAII,EAAMJ,MAAM,CAAA,CAAA,IAAA,CAC5BI,EAAMwD,QAAQxD,EAAMyD,KAAAA;AAAAA;AAG3D,SAAgB8L,cAAcvP,GAAAA;AAC5B,SAAOA,aAAiBsP,SAAYtP,IAAQwP,gBAAWC,WAAWzP,CAAAA;AAAAA;AAGpE,SAcgB0P,eACZ1P,GAAqBuD,GAAAA;AAAAA,MAACoM,IAAAA,EAAAA,CAAAA,GAASC,IAAAA,EAAAA,CAAAA,GAE3BrC,IAAAA,yBAAAA,CAAAA,GAAC/J,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GACToM,IAAeD,IAAUD,GAE3B/B,IAAAA,CAAAA,GAAAA,GAAAA,GAAAA,CAAAA,GAACkC,IAAAA,EAAAA,CAAAA,GAAMC,IAAAA,EAAAA,CAAAA,GAAMC,IAAAA,EAAAA,CAAAA,GAAMC,IAAAA,EAAAA,CAAAA;AAsBvB,SAvBexM,IAAQD,IAEVqM,KAEXC,IAAO,GACPC,IAAO,GACPC,IAAOnO,KAAKoF,MAAM,OAAO4I,IAAerM,IAASC,EAAAA,GACjDwM,IAAOpO,KAAKoF,MAAM,OAAO4I,IAAerM,IAASC,EAAAA,MAGjDqM,IAAOjO,KAAKoF,MAAM,OAAQ,IAAM4I,IAAgBpM,IAAQD,EAAAA,GACxDuM,IAAOlO,KAAKoF,MAAM,OAAQ,IAAM4I,IAAgBpM,IAAQD,EAAAA,GACxDwM,IAAO,GACPC,IAAO,IAAA,EAUDC,SAPqBjQ,KAAQ,WAAA;AACnC,QAAIkQ,KAAcZ,cAAcvP,CAAAA;AAGhC,WAFAmQ,KAAcC,MAASD,IAAAA,CAAAA,CAAeL,GAAMC,CAAAA,GAAAA,CAAQC,GAAMC,CAAAA,GAAAA,CAAQ,GAAG,CAAA,CAAA,CAAA,GAE9DI,MAASC,eAAeH,IAAAA,CAAcR,GAASC,CAAAA,CAAAA;EAAAA,CAAAA,GAGvCW,SAAAA,EAAUC,KAAKV,GAAMW,MAAMT,GAAMU,OAAOT,GAAMU,QAAQZ,EAAAA,EAAAA;AAAAA;AAGzE,SAAgBa,kBACZnI,GAAelF,GACfgK,GACAgD,GAAkBM,GAAAA;AAAAA,MAFFrN,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GACvBqN,IAAAA,EAAAA,CAAAA,GAAuBC,IAAAA,EAAAA,CAAAA,GAOpBC,IACFzC,WAAW9F,IALVjF,IAAS+M,EAAQC,MAAMD,EAAQI,UAAAA,IAE/BlN,IAAQ8M,EAAQE,OAAOF,EAAQG,SAAAA,GAAAA,CAGGH,EAAQC,KAAAA,CAAMD,EAAQE,IAAAA;AAE7D,SAAII,IACKnC,oBAAoBsC,GAAavN,CAAAA,IAEjCuN;AAAAA;ACjLX,IAAMC,sBAAAA,EACJC,cAAc,eACd1R,cAAc,IACd+M,YAAY,MACZqC,iBAAiB,IAAA;AAJnB,IAOMuC,qBAAAA,CAAsB,eAAe,UAAA;AAP3C,IAQMC,eAAAA,EACJC,aAAAA,CAAgB,GAAG,IAAI,EAAA,GACvBC,UAAAA,CAAa,IAAI,EAAA,EAAA;AAVnB,IAaMC,mBAAAA,EACJF,aAAAA,CAAgB,KAAM,MAAM,CAAA,GAC5BC,UAAAA,CAAa,CAAA,EAAA;AAff,IAiBME,oBAAAA,CAAqB,GAAG,GAAG,CAAA;AAEjC,SAASC,oBAAoBC,GAAAA;AAM3B,MAH2B,SAF3BA,IAASA,KAAUT,qBAERC,iBACTQ,EAAOR,eAAe,gBAEpBC,mBAAmBjC,QAAQwC,EAAOR,YAAAA,IAAgB,EACpD,OAAM,IAAIS,MACN,0BAAwBD,EAAOR,eAAAA,wBACXC,kBAAAA;AAY1B,MAT8B,QAA1BO,EAAO9C,oBACT8C,EAAO9C,kBAAkB,MAG3BE,wBAAwB4C,EAAO9C,eAAAA,GAEJ,QAAvB8C,EAAOlS,iBACTkS,EAAOlS,eAAe,KAEpB4R,aAAaM,EAAOR,YAAAA,EAAchC,QAAQwC,EAAOlS,YAAAA,IAAgB,EACnE,OAAM,IAAImS,MACN,0BAAwBD,EAAOlS,eAAAA,wBACX4R,aAAaM,EAAOR,YAAAA,IAAAA,uBACpBQ,EAAOR,eAAAA,GAAAA;AAMjC,MAHyB,QAArBQ,EAAOnF,eACTmF,EAAOnF,aAAa,IAElBgF,iBAAiBG,EAAOR,YAAAA,EAAchC,QAAQwC,EAAOnF,UAAAA,IAAc,EACrE,OAAM,IAAIoF,MACN,wBAAsBD,EAAOnF,aAAAA,wBACTgF,iBAAiBG,EAAOR,YAAAA,IAAAA,uBACxBQ,EAAOR,eAAAA,GAAAA;AAMjC,MAHyB,QAArBQ,EAAOtF,eACTsF,EAAOtF,aAAa,IAElBoF,kBAAkBtC,QAAQwC,EAAOtF,UAAAA,IAAc,EACjD,OAAM,IAAIuF,MACN,wBAAsBD,EAAOtF,aAAAA,wBACToF,oBAAAA,uBACAE,EAAOR,eAAAA,GAAAA;AAGjC,MAA4B,kBAAxBQ,EAAOR,gBAA0D,OAAxBQ,EAAOlS,gBAC1B,MAAtBkS,EAAOnF,WACT,OAAM,IAAIoF,MACN,yEAAA;AAIN,SAAOD;AAAAA;AAkDT,IAAaE,iCAAAA,EACXf,gBAAAA,MAAgB;AADlB,IAIagB,gCAAAA,EACXhB,gBAAAA,OACAiB,eAAe,GACf1N,gBAAgB,KAChBiF,WAAW,GAAA;AAGb,SAGS0I,+BAA+BL,GAAAA;AAC/B,MAAAI,IAAAA,EAAAA,eAAe1N,IAAAA,EAAAA,gBAAgBiF,IAAAA,EAAAA;AAEtC,MAAIyI,KAAiB,EACnB,OAAM,IAAIH,MACN,2BAAyBG,IAAAA,iBAAAA;AAI/B,MAAI1N,IAAiB,KAAOA,IAAiB,EAC3C,OAAM,IAAIuN,MACN,4BAA0BvN,IAAAA,iCAAAA;AAIhC,MAAIiF,KAAa,EACf,OAAM,IAAIsI,MAAM,uBAAqBtI,IAAAA,GAAAA;AAAAA;AAIzC,IAAA,UAAA,WAAA;AAIE,WAAA,EAAY2I,IAAgBpD,GAAAA;AAC1BK,4BAAwB+C,GAAIxS,YAAAA,GAC5B4P,sBAAsBR,GAAiBoD,GAAIxS,YAAAA,GAE3CC,KAAKwS,YAAYD,IACjBvS,KAAKmP,kBAAkBA;EAAAA;AA0I3B,SAnHQsD,EAAAA,UAAAA,wBAAN,SACIlS,IACA0R,GAAAA;AAAAA,WAAAA,WAAAA,MAAAA,IAAAA,gCAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,UAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA;AAAAA,aAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAAAA,gBAAAA,EAAAA,OAAAA;UAAAA,KAAAA;AAmBuB,mBAjBnBS,IAAAA,SAAAA,CAAAA,GACDN,+BACAH,CAAAA,GAGLK,+BAA+BL,CAAAA,GAEzBlS,IAAeC,KAAKwS,UAAUzS,cAC9BoP,IAAkBnP,KAAKmP,iBAEvBrL,IAAkB8L,yBAAyBrP,EAAAA,GAA1CwD,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GAET8J,IAAqBmC,eAAe1P,IAAO4O,CAAAA,GAA1CsB,IAAAA,EAAAA,SAASK,IAAAA,EAAAA,SAEV3C,IACFnO,KAAKwS,UAAUxR,QAAQyP,CAAAA,GADpBnP,IAAAA,EAAAA,eAAeG,IAAAA,EAAAA,SAASC,IAAAA,EAAAA,iBAAiBC,IAAAA,EAAAA,iBAAAA,CAAAA,GAGjB0M,kBAAAA,CAC1B/M,GAAeG,GAASC,GAAiBC,CAAAA,CAAAA,CAAAA;UAAAA,KAAAA;AAOhC,mBARRsK,IAAmB0G,EAAAA,KAAAA,GAGnB/K,IAAeqE,EAAiB,CAAA,GAChCzC,IAAgByC,EAAiB,CAAA,GACjCxC,IAAyBwC,EAAiB,CAAA,GAC1CvC,IAAyBuC,EAAiB,CAAA,GAAA,CAAA,GAE5B1C,oBAChB3B,GAAc4B,GAAeC,GAC7BC,GAAwB3J,GAAc2S,EAAmBL,eACzDK,EAAmB/N,gBAAgB+N,EAAmB9I,SAAAA,CAAAA;UAAAA,KAAAA;AAY1D,mBAfMZ,IAAQ2J,EAAAA,KAAAA,GAKRC,IAAczB,kBAChBnI,GAAAA,CAAQjF,GAAQC,CAAAA,GAAQmL,GAAiB2B,GACzC4B,EAAmBtB,cAAAA,GAEvB9P,EAAcM,QAAAA,GACdH,EAAQG,QAAAA,GACRF,EAAgBE,QAAAA,GAChBD,EAAgBC,QAAAA,GAChB6O,EAAQ7O,QAAAA,GAAAA,CAAAA,GAEDgR,CAAAA;QAAAA;MAAAA,CAAAA;IAAAA,CAAAA;EAAAA,GAqBHH,EAAAA,UAAAA,qBAAN,SACIlS,IACA0R,GAAAA;AAAAA,WAAAA,WAAAA,MAAAA,IAAAA,iCAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,UAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA;AAAAA,aAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAAAA,gBAAAA,EAAAA,OAAAA;UAAAA,KAAAA;AAgBW,mBAdPS,IAAAA,SAAAA,CAAAA,GAAyBP,gCAAmCF,CAAAA,GAI5DlS,IAAeC,KAAKwS,UAAUzS,cAC9BoP,IAAkBnP,KAAKmP,iBAEvBrL,IAAkB8L,yBAAyBrP,EAAAA,GAA1CwD,IAAAA,EAAAA,CAAAA,GAAQC,IAAAA,EAAAA,CAAAA,GAET8J,IAAqBmC,eAAe1P,IAAO4O,CAAAA,GAA1CsB,IAAAA,EAAAA,SAASK,IAAAA,EAAAA,SAEV3C,IACFnO,KAAKwS,UAAUxR,QAAQyP,CAAAA,GADpBnP,IAAAA,EAAAA,eAAeG,IAAAA,EAAAA,SAASC,IAAAA,EAAAA,iBAAiBC,IAAAA,EAAAA,iBAAAA,CAAAA,GAG7BgK,iBAAiBrK,GAAeG,GAAS1B,CAAAA,CAAAA;UAAAA,KAAAA;AAa5D,mBAbM0O,IAAOkE,EAAAA,KAAAA,GAGPC,IAAczB,kBAAAA,CAFL1C,CAAAA,GAAAA,CAGH1K,GAAQC,CAAAA,GAAQmL,GAAiB2B,GACzC4B,EAAmBtB,cAAAA,GAEvB9P,EAAcM,QAAAA,GACdH,EAAQG,QAAAA,GACRF,EAAgBE,QAAAA,GAChBD,EAAgBC,QAAAA,GAChB6O,EAAQ7O,QAAAA,GAAAA,CAAAA,GAEDgR,EAAY,CAAA,CAAA;QAAA;MAAA,CAAA;IAAA,CAAA;EAAA,GAIfH,EAAAA,UAAAA,gBAAN,SACIlS,IACA0R,GAAAA;AAAAA,WAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,aAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAAAA,gBAAAA,EAAAA,OAAAA;UAAAA,KAAAA;AAAAA,mBAE4B,oBAA1BA,EAAOY,iBAAAA,CAAAA,GAAAA,CAAAA,IAAAA,CAAAA,GACU7S,KAAK8S,mBAAmBvS,IAAO0R,CAAAA,CAAAA;UAAAA,KAAAA;AAClD,mBAAA,CAAA,GAAA,CADanO,EAAAA,KAAAA,CAAAA,CAAAA;UAAAA,KAAAA;AAGb,mBAAA,CAAA,GAAO9D,KAAK+S,sBAAsBxS,IAAO0R,CAAAA,CAAAA;QAAAA;MAAAA,CAAAA;IAAAA,CAAAA;EAAAA,GAItCQ,EAAAA,UAAAA,UAAP,WAAA;AACEzS,SAAKwS,UAAU5Q,QAAAA;EAAAA,GAAAA;AAAAA,EAAAA;AAAAA,SAIJoR,cAAcf,GAAAA;AAAAA,SAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,QAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA;AAAAA,WAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAAAA,cAAAA,EAAAA,OAAAA;QAAAA,KAAAA;AAI3B,cAHMlS,IAAekS,EAAOlS,cACtB4M,IAAasF,EAAOtF,YACpBG,IAAamF,EAAOnF,YAChB,QAANmG,aACF,OAAM,IAAIf,MACN,gJAAA;AAMa,iBADbgB,IAAMrG,oBAAoB9M,GAAc+M,GAAYH,CAAAA,GAAAA,CAAAA,GACjCwG,eAAsBlB,EAAOmB,YAAYF,CAAAA,CAAAA;QAAAA,KAAAA;AAMlE,iBANMG,IAAavP,EAAAA,KAAAA,GACbwP,IAAY,IAAIxR,UAAUuR,GAAYtT,CAAAA,GAEtCwT,IAAuBjE,kCACzB2C,EAAO9C,iBAAiBmE,EAAUvT,YAAAA,GAAAA,CAAAA,GAE/B,IAAI0S,QAAQa,GAAWC,CAAAA,CAAAA;MAAAA;IAAAA,CAAAA;EAAAA,CAAAA;AAAAA;AAGhC,SAAeC,WAAWvB,GAAAA;AAAAA,SAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,QAAAA,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA;AAAAA,WAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAAAA,cAAAA,EAAAA,OAAAA;QAAAA,KAAAA;AAGxB,cAFMlS,IAAekS,EAAOlS,cACtB4M,IAAasF,EAAOtF,YAChB,QAANsG,aACF,OAAM,IAAIf,MACN,gJAAA;AAMa,iBADbgB,IAAMzG,mBAAmB1M,GAAc4M,CAAAA,GAAAA,CAAAA,GACpBwG,eAAsBlB,EAAOmB,YAAYF,CAAAA,CAAAA;QAAAA,KAAAA;AAIlE,iBAJMG,IAAavP,EAAAA,KAAAA,GACb2P,IAAS,IAAIrG,OAAOiG,GAAYtT,CAAAA,GAChCwT,IAAuBjE,kCACzB2C,EAAO9C,iBAAiBsE,EAAO1T,YAAAA,GAAAA,CAAAA,GAC5B,IAAI0S,QAAQgB,GAAQF,CAAAA,CAAAA;MAAAA;IAAAA,CAAAA;EAAAA,CAAAA;AAAAA;AAe7B,SAAsBG,KAAKzB,GAAAA;AAAAA,SAAAA,WAAAA,MAAAA,IAAAA,sBAAAA,UAAAA,MAAAA,QAAAA,QAAAA,WAAAA;AAAAA,WAAAA,YAAAA,MAAAA,SAAAA,GAAAA;AAGzB,aAA4B,gBAD5BA,IAASD,oBAAoBC,CAAAA,GAClBR,eAAAA,CAAAA,GACF+B,WAAWvB,CAAAA,CAAAA,IACe,kBAAxBA,EAAOR,eAAAA,CAAAA,GACTuB,cAAcf,CAAAA,CAAAA,IAAAA,CAAAA,GAEd,IAAA;IAAA,CAAA;EAAA,CAAA;AAAA;ACncX,IAAM0B,UAAU;",
  "names": ["model", "outputStride", "this", "inputShape", "inputs", "shape", "tf.util", "assert", "BaseModel", "input", "tf.tidy", "asFloat", "_this", "preprocessInput", "tf.cast", "asBatch", "tf.expandDims", "results3d", "predict", "map", "y", "tf.squeeze", "namedResults", "nameOutputResults", "heatmapScores", "tf.sigmoid", "heatmap", "offsets", "displacementFwd", "displacementBwd", "dispose", "tslib_1.__extends", "MobileNet", "tf.sub", "tf.div", "results", "half", "k", "Math", "floor", "maxSize", "getElementValue", "priorityQueue", "Array", "numberOfElements", "MaxHeap", "x", "swim", "max", "exchange", "sink", "slice", "less", "j", "i", "getValueAt", "t", "scoreIsMaximumInLocalWindow", "keypointId", "score", "heatmapY", "heatmapX", "localMaximumRadius", "scores", "_a", "height", "width", "localMaximum", "yStart", "yEnd", "min", "yCurrent", "xStart", "xEnd", "xCurrent", "get", "buildPartWithScoreQueue", "scoreThreshold", "numKeypoints", "queue", "e", "enqueue", "part", "id", "partNames", "NUM_KEYPOINTS", "length", "partIds", "reduce", "result", "jointName", "connectedPartNames", "poseChain", "connectedPartIndices", "jointNameA", "jointNameB", "partChannels", "getOffsetPoint", "keypoint", "getImageCoords", "clamp", "a", "squaredDistance", "y1", "x1", "y2", "x2", "dy", "dx", "addVectors", "b", "parentChildrenTuples", "parentJoinName", "childJoinName", "parentToChildEdges", "childToParentEdges", "getDisplacement", "edgeId", "point", "displacements", "numEdges", "getStridedIndexNearPoint", "round", "traverseToTargetKeypoint", "sourceKeypoint", "targetKeypointId", "scoresBuffer", "offsetRefineStep", "displacement", "position", "targetKeypoint", "targetKeypointIndices", "offsetPoint", "targetKeyPointIndices", "decodePose", "root", "displacementsFwd", "displacementsBwd", "numParts", "instanceKeypoints", "rootPart", "rootScore", "rootPoint", "edge", "sourceKeypointId", "withinNmsRadiusOfCorrespondingPoint", "poses", "squaredNmsRadius", "some", "correspondingKeypoint", "getInstanceScore", "existingPoses", "kLocalMaximumRadius", "decodeMultiplePoses", "offsetsBuffer", "displacementsFwdBuffer", "displacementsBwdBuffer", "maxPoseDetections", "nmsRadius", "empty", "dequeue", "keypoints", "push", "mod", "floored", "tf.scalar", "tf.mul", "argmax2d", "depth", "reshaped", "tf.reshape", "coords", "tf.argMax", "yCoords", "xCoords", "tf.concat", "getPointsConfidence", "heatMapCoords", "Float32Array", "getOffsetVectors", "heatMapCoordsBuffer", "valueOf", "tf.tensor2d", "getOffsetPoints", "offsetVectors", "tf\r\n            .add", "tf\r\n            .cast", "tf\r\n            .mul", "toTensor", "decodeSinglePose", "totalScore", "heatmapValues", "Promise", "all", "buffer", "allTensorBuffers", "heatmapValuesBuffer", "offsetPoints", "offsetPointsBuffer", "keypointConfidence", "from", "MOBILENET_BASE_URL", "RESNET50_BASE_URL", "resNet50Checkpoint", "stride", "quantBytes", "graphJson", "mobileNetCheckpoint", "multiplier", "toStr", "1", "0.75", "0.5", "imageNetMean", "ResNet", "tf.add", "eitherPointDoesntMeetConfidence", "minConfidence", "getAdjacentKeyPoints", "leftJoint", "rightJoint", "NEGATIVE_INFINITY", "POSITIVE_INFINITY", "getBoundingBox", "_b", "maxX", "maxY", "minX", "minY", "_c", "getBoundingBoxPoints", "toTensorBuffers3D", "tensors", "tensor", "scalePose", "pose", "scaleY", "scaleX", "offsetY", "offsetX", "scalePoses", "flipPoseHorizontal", "imageWidth", "flipPosesHorizontal", "toValidInputResolution", "inputResolution", "isValidInputResolution", "validateInputResolution", "getValidInputResolutionDimensions", "VALID_OUTPUT_STRIDES", "assertValidOutputStride", "indexOf", "resolution", "assertValidResolution", "getInputTensorDimensions", "tf.Tensor", "toInputTensor", "tf.browser", "fromPixels", "padAndResizeTo", "targetH", "targetW", "targetAspect", "padT", "padB", "padL", "padR", "resized", "imageTensor", "tf.pad3d", "tf.image", "resizeBilinear", "padding", "top", "left", "right", "bottom", "scaleAndFlipPoses", "flipHorizontal", "inputResolutionHeight", "inputResolutionWidth", "scaledPoses", "MOBILENET_V1_CONFIG", "architecture", "VALID_ARCHITECTURE", "VALID_STRIDE", "MobileNetV1", "ResNet50", "VALID_MULTIPLIER", "VALID_QUANT_BYTES", "validateModelConfig", "config", "Error", "SINGLE_PERSON_INFERENCE_CONFIG", "MULTI_PERSON_INFERENCE_CONFIG", "maxDetections", "validateMultiPersonInputConfig", "net", "baseModel", "PoseNet", "configWithDefaults", "_d", "resultPoses", "decodingMethod", "estimateSinglePose", "estimateMultiplePoses", "loadMobileNet", "tf", "url", "tfconv.loadGraphModel", "modelUrl", "graphModel", "mobilenet", "validInputResolution", "loadResNet", "resnet", "load", "version"]
}
